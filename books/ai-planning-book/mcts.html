<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Online search: MCTS - AI Planning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="simple-planning.html"><strong aria-hidden="true">1.</strong> Simple planning</a></li><li class="chapter-item expanded "><a href="classical-planning.html"><strong aria-hidden="true">2.</strong> Classical planning</a></li><li class="chapter-item expanded "><a href="planning-in-a-stochastic-environment.html"><strong aria-hidden="true">3.</strong> Planning in a stochastic environment</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="value-iteration.html"><strong aria-hidden="true">3.1.</strong> Value iteration</a></li><li class="chapter-item expanded "><a href="policy-iteration.html"><strong aria-hidden="true">3.2.</strong> Policy iteration</a></li><li class="chapter-item expanded "><a href="gpi.html"><strong aria-hidden="true">3.3.</strong> GPI</a></li><li class="chapter-item expanded "><a href="mcts.html" class="active"><strong aria-hidden="true">3.4.</strong> Online search: MCTS</a></li></ol></li><li class="chapter-item expanded "><a href="learning-to-plan-in-a-stochastic-environment.html"><strong aria-hidden="true">4.</strong> Learning to plan in a stochastic environment</a></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">4.1.</strong> Learning the transition model (model-based RL)</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.2.</strong> Learning the Q-function (model-free RL)</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">4.2.1.</strong> MC learning</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">4.2.1.1.</strong> Direct utility estimation</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.2.1.2.</strong> MC control with GPI</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.2.1.3.</strong> GLIE epsilon-greedy MC control</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.2.2.</strong> TD learning</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="sarsa.html"><strong aria-hidden="true">4.2.2.1.</strong> SARSA</a></li><li class="chapter-item expanded "><a href="q-learning.html"><strong aria-hidden="true">4.2.2.2.</strong> Q-learning</a></li><li class="chapter-item expanded "><a href="deep-q-learning.html"><strong aria-hidden="true">4.2.2.3.</strong> Deep Q-learning</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="learning-the-policy.html"><strong aria-hidden="true">4.3.</strong> Learning the policy</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="reinforce.html"><strong aria-hidden="true">4.3.1.</strong> REINFORCE</a></li><li class="chapter-item expanded "><a href="reinforce-with-baseline.html"><strong aria-hidden="true">4.3.2.</strong> REINFORCE with baseline</a></li><li class="chapter-item expanded "><a href="actor-critic.html"><strong aria-hidden="true">4.3.3.</strong> Actor critic</a></li><li class="chapter-item expanded "><a href="trpo.html"><strong aria-hidden="true">4.3.4.</strong> TRPO</a></li><li class="chapter-item expanded "><a href="ppo.html"><strong aria-hidden="true">4.3.5.</strong> PPO</a></li><li class="chapter-item expanded "><a href="imitation-learning.html"><strong aria-hidden="true">4.3.6.</strong> Imitation learning</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="planning-in-a-stochastic-environment-with-partial-observability.html"><strong aria-hidden="true">5.</strong> Planning in a stochastic environment with partial observability</a></li><li class="chapter-item expanded "><a href="planning-in-a-multi-agent-environment.html"><strong aria-hidden="true">6.</strong> Planning in a multi-agent environment</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="single-move-games.html"><strong aria-hidden="true">6.1.</strong> Single-move / simultaneous games</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="2-player-non-zero-sum-games.html"><strong aria-hidden="true">6.1.1.</strong> 2-player non-zero-sum games</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.1.2.</strong> 2-player zero-sum games</div></li><li class="chapter-item expanded "><a href="other-games.html"><strong aria-hidden="true">6.1.3.</strong> Other games</a></li></ol></li><li class="chapter-item expanded "><a href="sequential-games.html"><strong aria-hidden="true">6.2.</strong> Sequential games</a></li><li class="chapter-item expanded "><a href="repeated-games.html"><strong aria-hidden="true">6.3.</strong> Repeated games</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><li class="part-title">Reinforcement learning</li><li class="chapter-item expanded "><a href="on-vs-off-policy-learning.html"><strong aria-hidden="true">7.</strong> On-policy vs. off-policy learning</a></li><li class="chapter-item expanded "><a href="exploration-algorithms.html"><strong aria-hidden="true">8.</strong> Exploration algorithms</a></li><li class="chapter-item expanded "><a href="deadly-triad.html"><strong aria-hidden="true">9.</strong> Deadly triad</a></li><li class="chapter-item expanded "><a href="function-approximation.html"><strong aria-hidden="true">10.</strong> Function approximation</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Appendix</li><li class="chapter-item expanded "><a href="decision-theory.html"><strong aria-hidden="true">11.</strong> Decision theory</a></li><li class="chapter-item expanded "><a href="principal-of-optimality.html"><strong aria-hidden="true">12.</strong> Principal of optimality</a></li><li class="chapter-item expanded "><a href="counting.html"><strong aria-hidden="true">13.</strong> Counting</a></li><li class="chapter-item expanded "><a href="mdp.html"><strong aria-hidden="true">14.</strong> MDP</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">AI Planning</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="online-search-mcts"><a class="header" href="#online-search-mcts">Online search: MCTS</a></h1>
<p>Sample a problem space randomly and repeatedly in order to obtain a more accurate understanding (&quot;<strong>statistics</strong>&quot;) and to decide which action to take next.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/78109082-b562-4648-b767-be5e484ddbce/video-output-19879316-4B55-4C39-99C9-7201375BE911.mov">https://s3-us-west-2.amazonaws.com/secure.notion-static.com/78109082-b562-4648-b767-be5e484ddbce/video-output-19879316-4B55-4C39-99C9-7201375BE911.mov</a></p>
<p>Q-function in MCTS is defined as</p>
<p>$$
Q(s,a) = \text{#returns}
$$</p>
<p>And the action to take at state <em>s</em> is</p>
<p>$$
\pi(n) = \arg \max_{a \in A} Q(n,a)
$$</p>
<ol>
<li>
<p><strong>Select a node</strong></p>
<p>The policy to follow is \( \pi_{UCT} \). Calculate UCT (Upper Confidence Tree) for every child</p>
<p>$$
UCT =  \text{exploitation} + C \times \text{exploration}
$$</p>
<p>where</p>
<p>$$
\text{exploitation} = \frac{v_i}{n_i} \\
\text{exploration} = \sqrt \frac{\log N}{n_i}
$$</p>
<p>and where</p>
<ul>
<li>\( v_i \) is the sum of the returns from the \( i \)th child</li>
<li>\( n_i \) is the no. of visits of the \( i \)th child</li>
<li>\( N \) is the no. of visits of the current node</li>
</ul>
</li>
<li>
<p><strong>Expand</strong></p>
<p>At this node, we select an action that hasn't been taken. Selecting that action means we will enter the state.</p>
</li>
<li>
<p><strong>Simulate</strong></p>
<p>In this part, the policy to follow is usually a uniform random policy.</p>
</li>
<li>
<p><strong>Backprop</strong></p>
<p>Update rewards and n_visits.</p>
</li>
</ol>
<pre><code class="language-python">from __future__ import annotations
import numpy as np
from operator import itemgetter
import random

ACTIONS = [3, 2, 1, 0]
N_ACTIONS = len(ACTIONS)

class MonteCarloTree:
    def __init__(self, state, depth=0):
        self.n_visits = 0
        self.rewards = 0
        self.children = []
        self.actions_not_taken = ACTIONS.copy()
        self.state = state.copy()
        self.depth = depth
        self.is_terminal = False

        # to keep track of nodes needed for backprop
        # root node's responsibility
        self.stack = Stack()

    @property
    def deets(self):
        print(f&quot;Fully expanded: {self.is_fully_expanded}&quot;)
        print(f&quot;Depth: {self.depth}&quot;)
        print(f&quot;Visits: {self.n_visits}&quot;)
        print(f&quot;Rewards: {self.rewards}&quot;)

    def find_best_action(self,
                         max_depth=1,
                         n_rollouts=20,
                         **infos) -&gt; int:
        &quot;&quot;&quot;Only the root node should be calling this&quot;&quot;&quot;

        # 1. Perform rollouts
        for rollout_number in range(n_rollouts):
            print(rollout_number)
            # Step 1
            node = self.select(max_depth)
            # Step 2
            node = self.expand(node, **infos)
            # Step 3
            rewards = self.rollout(node, **infos)
            # Step 4
            self.backprop(rewards)

        # 2. Return action that had many visits
        visits = [child.n_visits for child in self.children]
        action, _ = max(enumerate(visits), key=itemgetter(1))

        return action

    def select(self, max_depth) -&gt; MonteCarloTree:
        &quot;&quot;&quot;
        Traverse from root
        If no. of children less than no. of actions, create new node.
        Otherwise, do UCT
        Only the root node should be calling this
        &quot;&quot;&quot;
        node = self
        self.stack.push(node)

        while node.is_fully_expanded and node.depth &lt; max_depth:
            node = node.find_best_child_uct()
            self.stack.push(node)

        return node

    def expand(self, node, **infos) -&gt; MonteCarloTree:
        &quot;&quot;&quot;
        Only the root node should be calling this
        Return a child node
        &quot;&quot;&quot;
        action = node.actions_not_taken.pop()
        state_new = self.get_next_state(state=node.state, action=action, **infos)

        child = MonteCarloTree(state=state_new, depth=node.depth+1)
        self.children.append(child)
        self.stack.push(child)

        return child

    def rollout(self, node, **infos) -&gt; int:
        &quot;&quot;&quot;
        Only the root node should be calling this
        Play the game and return the reward
        &quot;&quot;&quot;
        sim = Simulator.create(node.state, infos[&quot;max_speed&quot;])
        reward = sim.step_through(node.state)
        return reward

    def backprop(self, rewards):
        &quot;&quot;&quot;Only the root node should be calling this&quot;&quot;&quot;
        while self.stack.is_not_empty:
            node = self.stack.pop()
            node.n_visits += 1
            node.rewards += rewards

    def find_best_child_uct(self) -&gt; MonteCarloTree:
        return self.children[0]

    @property
    def is_fully_expanded(self):
        return not self.actions_not_taken

    def get_next_state(self, state, action, **infos):
        sim = Simulator.create(state, infos[&quot;max_speed&quot;])
        reward = sim.step(action)
        return reward

class Stack:
    def __init__(self):
        self.data = []

    def push(self, val):
        self.data.append(val)

    def pop(self):
        return self.data.pop()

    @property
    def is_not_empty(self):
        return len(self.data) &gt; 0

class Simulator:
    def __init__(self, state, max_speeds):
        self.state = state
        self.max_speeds = max_speeds

    @classmethod
    def create(cls, state, max_speeds):
        return cls(state, max_speeds)

    def step(self, action) -&gt; int:
        &quot;&quot;&quot;Environment and agent&quot;&quot;&quot;

        # Environment
        speeds = [random.randint(1, max_speed)
                  for max_speed in self.max_speeds]
        next_state = predict(self.state,
                             speeds=speeds,
                             agent_coord=(None, None),
                             include_occupancy=True)
        self.state = next_state

        # Agent
        x, y = np.where(self.state[1] == 1)
        x, y = x[0], y[0]
        if action == 0:
            x = x-1
            y = y-1
        elif action == 1:
            x = x+1
        elif action == 2:
            y = y-3
        elif action == 3:
            y = y-2
        elif action == 4:
            y = y-1
        else:
            raise ValueError
        x = np.clip(x, 0, 9)
        y = np.clip(y, 0, 49)

        # State, reward, done
        if (x, y) == (0, 0):
            return 10, True
        elif next_state[0, x, y] == 1:
            return 0, True
        else:
            return 0, False

    def step_through(self, action) -&gt; int:
        done = False
        while not done:
            reward, done = self.step(action)
        return reward
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="gpi.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="learning-to-plan-in-a-stochastic-environment.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="gpi.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="learning-to-plan-in-a-stochastic-environment.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
