<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>ai-book</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Domains / data</li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.</strong> General</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="general/eda.html"><strong aria-hidden="true">1.1.</strong> EDA</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.2.</strong> Processing</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.3.</strong> Tasks</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="anomaly-detection.html"><strong aria-hidden="true">1.3.1.</strong> Anomaly detection</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.</strong> Vision</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">2.1.</strong> EDA</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.2.</strong> Processing</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.</strong> Tasks</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.1.</strong> Image classification</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.2.</strong> Semantic segmentation</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.3.</strong> Object detection</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.4.</strong> Instance segmentation</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.5.</strong> Pose estimation</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.6.</strong> Hand pose estimation</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.3.7.</strong> Reidentification</div></li><li class="chapter-item expanded "><a href="ui.html"><strong aria-hidden="true">2.3.8.</strong> UI</a></li></ol></li><li class="chapter-item expanded "><a href="computer-vision/models.html"><strong aria-hidden="true">2.4.</strong> Models</a></li><li class="chapter-item expanded "><a href="prompt-engineering.html"><strong aria-hidden="true">2.5.</strong> Prompt engineering</a></li></ol></li><li class="chapter-item expanded "><a href="language.html"><strong aria-hidden="true">3.</strong> Language</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="processing.html"><strong aria-hidden="true">3.1.</strong> Processing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tokenisation.html"><strong aria-hidden="true">3.1.1.</strong> Tokenisatin</a></li><li class="chapter-item expanded "><a href="embeddings.html"><strong aria-hidden="true">3.1.2.</strong> Embeddings</a></li><li class="chapter-item expanded "><a href="encoding.html"><strong aria-hidden="true">3.1.3.</strong> Encoding</a></li><li class="chapter-item expanded "><a href="representation.html"><strong aria-hidden="true">3.1.4.</strong> Representation</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">3.2.</strong> Tasks</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="language-modelling.html"><strong aria-hidden="true">3.2.1.</strong> Language modelling</a></li><li class="chapter-item expanded "><a href="topic-modelling.html"><strong aria-hidden="true">3.2.2.</strong> Topic modelling</a></li><li class="chapter-item expanded "><a href="sequence-modelling.html"><strong aria-hidden="true">3.2.3.</strong> Sequence modelling</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">3.3.</strong> Tasks</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">3.3.1.</strong> Common sense reasoning</div></li><li class="chapter-item expanded "><a href="summarisation.html"><strong aria-hidden="true">3.3.2.</strong> Summarisation</a></li><li class="chapter-item expanded "><a href="machine-translation.html"><strong aria-hidden="true">3.3.3.</strong> Machine translation</a></li></ol></li><li class="chapter-item expanded "><a href="pretraining.html"><strong aria-hidden="true">3.4.</strong> Pretraining tasks</a></li><li class="chapter-item expanded "><a href="nlp/models.html"><strong aria-hidden="true">3.5.</strong> Models</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.</strong> Multimodal</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="multimodal/pretraining.html"><strong aria-hidden="true">4.1.</strong> Pretraining tasks</a></li><li class="chapter-item expanded "><a href="multimodal/models.html"><strong aria-hidden="true">4.2.</strong> Models</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.</strong> Planning</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.</strong> Graph mining</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">7.</strong> Time series</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">8.</strong> Audio</div></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Concepts</li><li class="chapter-item expanded "><div><strong aria-hidden="true">9.</strong> Knowledge distillation</div></li><li class="spacer"></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.</strong> Classes of algorithms</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">10.1.</strong> Supervised learning</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.2.</strong> Unsupervised learning</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="clustering-algorithms.html"><strong aria-hidden="true">10.2.1.</strong> Clustering algorithms</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.2.2.</strong> Dimensionality reduction algorithms</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.3.</strong> n-shot learning</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> AutoML</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">12.</strong> Metrics</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">13.</strong> Loss functions</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">14.</strong> Hyperparameter optimisation</div></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">'Learning' types</li><li class="chapter-item expanded "><a href="self-supervised-learning.html"><strong aria-hidden="true">15.</strong> Self-supervised learning</a></li><li class="chapter-item expanded "><a href="semi-supervised-learning.html"><strong aria-hidden="true">16.</strong> Semi-supervised learning</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">17.</strong> Deep learning</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="intro-to-dl.html"><strong aria-hidden="true">17.1.</strong> Intro to DL</a></li><li class="chapter-item expanded "><a href="tensor-libraries.html"><strong aria-hidden="true">17.2.</strong> Tensor libraries</a></li><li class="chapter-item expanded "><a href="sparse-matrices.html"><strong aria-hidden="true">17.3.</strong> Sparse matrices</a></li><li class="chapter-item expanded "><a href="transfer-learning.html"><strong aria-hidden="true">17.4.</strong> Transfer learning</a></li><li class="chapter-item expanded "><a href="weight-initialisation.html"><strong aria-hidden="true">17.5.</strong> Weight initialisation</a></li><li class="chapter-item expanded "><a href="bonus-questions.html"><strong aria-hidden="true">17.6.</strong> Bonus questions</a></li><li class="chapter-item expanded "><a href="frameworks.html"><strong aria-hidden="true">17.7.</strong> Frameworks</a></li><li class="chapter-item expanded "><a href="improving-predictive-power.html"><strong aria-hidden="true">17.8.</strong> Improving predictive power</a></li><li class="chapter-item expanded "><a href="optimisers.html"><strong aria-hidden="true">17.9.</strong> SGD optimisers</a></li><li class="chapter-item expanded "><a href="limitations-and-new-frontiers.html"><strong aria-hidden="true">17.10.</strong> Limitations and new frontiers</a></li><li class="chapter-item expanded "><a href="learning-rate-scheduler.html"><strong aria-hidden="true">17.11.</strong> Learning rate scheduler</a></li><li class="chapter-item expanded "><a href="backpropagation-softmax-and-categorical-cross.html"><strong aria-hidden="true">17.12.</strong> Backpropagation softmax and categorical cross</a></li><li class="chapter-item expanded "><a href="hyperparameter-search.html"><strong aria-hidden="true">17.13.</strong> hyperparameter-search</a></li><li class="chapter-item expanded "><a href="layers.html"><strong aria-hidden="true">17.14.</strong> layers</a></li><li class="chapter-item expanded "><a href="improving-speed-accuracy.html"><strong aria-hidden="true">17.15.</strong> improving-speed-accuracy</a></li><li class="chapter-item expanded "><a href="activation-functions.html"><strong aria-hidden="true">17.16.</strong> Activation functions</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">18.</strong> Machine learning</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">19.</strong> Reinforcement learning</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">20.</strong> Bayesian learning</div></li><li class="chapter-item expanded "><a href="deep-generative-models.html"><strong aria-hidden="true">21.</strong> Deep generative models</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Models / algorithms</li><li class="chapter-item expanded "><div><strong aria-hidden="true">22.</strong> Association rule mining</div></li><li class="chapter-item expanded "><a href="decision-tree.html"><strong aria-hidden="true">23.</strong> Decision tree</a></li><li class="chapter-item expanded "><a href="dbscan.html"><strong aria-hidden="true">24.</strong> DBSCAN</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">25.</strong> Diffusion model</div></li><li class="chapter-item expanded "><a href="evolutionary-algorithms.html"><strong aria-hidden="true">26.</strong> Evolutionary algorithms</a></li><li class="chapter-item expanded "><a href="gaussian-process.html"><strong aria-hidden="true">27.</strong> Gaussian process</a></li><li class="chapter-item expanded "><a href="gmm.html"><strong aria-hidden="true">28.</strong> GMM</a></li><li class="chapter-item expanded "><a href="hierarchical-clustering.html"><strong aria-hidden="true">29.</strong> Hierachical clustering</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">30.</strong> HMM</div></li><li class="chapter-item expanded "><a href="gradient-boosting.html"><strong aria-hidden="true">31.</strong> Gradient boosting</a></li><li class="chapter-item expanded "><a href="k-nn.html"><strong aria-hidden="true">32.</strong> k-NN</a></li><li class="chapter-item expanded "><a href="k-means.html"><strong aria-hidden="true">33.</strong> k-means</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">34.</strong> KDE</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">35.</strong> LDA</div></li><li class="chapter-item expanded "><a href="linear-models.html"><strong aria-hidden="true">36.</strong> Linear models</a></li><li class="chapter-item expanded "><a href="logistic-regression.html"><strong aria-hidden="true">37.</strong> Logistic regression</a></li><li class="chapter-item expanded "><a href="mean-shift.html"><strong aria-hidden="true">38.</strong> Mean shift</a></li><li class="chapter-item expanded "><a href="naive-bayes.html"><strong aria-hidden="true">39.</strong> Naive Bayes</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">40.</strong> Neural networks</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">40.1.</strong> MLP</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">40.2.</strong> CNN</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">40.3.</strong> RNN</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">40.4.</strong> LSTM</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">40.5.</strong> Transformer</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">40.6.</strong> GAN</div></li></ol></li><li class="chapter-item expanded "><a href="pca.html"><strong aria-hidden="true">41.</strong> PCA</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">42.</strong> PGM</div></li><li class="chapter-item expanded "><a href="svm.html"><strong aria-hidden="true">43.</strong> SVM</a></li><li class="chapter-item expanded "><a href="t-sne.html"><strong aria-hidden="true">44.</strong> t-SNE</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">45.</strong> Tree ensembles</div></li><li class="chapter-item expanded "><a href="umap.html"><strong aria-hidden="true">46.</strong> UMAP</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Representations</li><li class="chapter-item expanded "><div><strong aria-hidden="true">47.</strong> Distance metric</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">48.</strong> Similarity search</div></li><li class="chapter-item expanded "><a href="similarity-measures.html"><strong aria-hidden="true">49.</strong> Similarity measures</a></li><li class="chapter-item expanded "><a href="dimensionality-reduction.html"><strong aria-hidden="true">50.</strong> Dimensionality reduction</a></li><li class="chapter-item expanded "><a href="ann.html"><strong aria-hidden="true">51.</strong> ANN</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Tasks / problems</li><li class="chapter-item expanded "><a href="survival-analysis.html"><strong aria-hidden="true">52.</strong> Survival analysis</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">53.</strong> Market basket analysis</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">54.</strong> Recommender system</div></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">System design</li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Others</li><li class="chapter-item expanded "><a href="concept-drift.html"><strong aria-hidden="true">55.</strong> Concept drift</a></li><li class="chapter-item expanded "><a href="interpretable-ai.html"><strong aria-hidden="true">56.</strong> Interpretable AI</a></li><li class="chapter-item expanded "><a href="adversarial-ai.html"><strong aria-hidden="true">57.</strong> Adversarial AI</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">ai-book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="eda"><a class="header" href="#eda">EDA</a></h1>
<p><a href="https://www.kaggle.com/gunesevitan/titanic-advanced-feature-engineering-tutorial">https://www.kaggle.com/gunesevitan/titanic-advanced-feature-engineering-tutorial</a></p>
<ul>
<li>Missing values
<ul>
<li>Fill using information from correlation</li>
<li>Fill using group information</li>
<li>Fill via knowledge (search)</li>
<li>Fill via heuristics (how a value is obtained in the real world)</li>
</ul>
</li>
<li>Importance of visualisation in the right angle</li>
<li>Distribution of a feature with hue=(train, test)</li>
<li>Remarks</li>
<li>Engineering features based on <em>information gain</em> (against target).</li>
<li>High cardinality indicates that a lot of feature engineering can be done. Convert high cardinality to count. (Is it always okay?)</li>
<li>Create a feature that is your own proxy of the target variable.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="anomaly-detection"><a class="header" href="#anomaly-detection">Anomaly detection</a></h1>
<p><a href="https://scikit-learn.org/stable/modules/outlier_detection.html#">https://scikit-learn.org/stable/modules/outlier_detection.html#</a></p>
<p><a href="https://github.com/arundo/adtk">https://github.com/arundo/adtk</a></p>
<p>Methods</p>
<ul>
<li>Outlier detection: training data already contains outliers
<ul>
<li>Local outlier factor</li>
<li>Isolation forest</li>
<li>One-class SVM</li>
<li>Robust covariance</li>
</ul>
</li>
<li>Novelty detection: training data not polluted by outliers
<ul>
<li>One-class SVM</li>
<li>Local outlier factor</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ui"><a class="header" href="#ui">UI</a></h1>
<ul>
<li>Widget captioning</li>
<li>Screen summarisation</li>
<li>Command grounding</li>
</ul>
<p>https://ai.googleblog.com/2023/02/a-vision-language-approach-for.html</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="models"><a class="header" href="#models">Models</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Year</th><th>Model</th><th>Modes</th><th>Architecture</th><th>Params</th></tr></thead><tbody>
<tr><td>2022</td><td>Mid Journey</td><td></td><td></td><td></td></tr>
<tr><td>2021</td><td>Latent Diffusion</td><td></td><td></td><td></td></tr>
<tr><td>2020</td><td>StyleGAN</td><td>Image</td><td>GAN</td><td></td></tr>
<tr><td></td><td>ViT</td><td>Image?</td><td>Transformer</td><td></td></tr>
<tr><td>2018</td><td>EfficientNet</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>BigGAN</td><td></td><td>GAN</td><td></td></tr>
<tr><td>2017</td><td>ResNeXt-50</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>Mask R-CNN</td><td>Image</td><td>Object detection</td><td></td></tr>
<tr><td>2016</td><td>Xception</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>Inception-v4</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>Inception-ResNet-V2</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>DenseNet</td><td>Image</td><td></td><td></td></tr>
<tr><td>2015</td><td>Inception-v3</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>ResNet-50</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>U-Net</td><td>Image</td><td>Encoder-decoder</td><td></td></tr>
<tr><td></td><td>DCGAN</td><td>Image</td><td>GAN</td><td></td></tr>
<tr><td>2014</td><td>VGG-16</td><td>Image</td><td></td><td>138M</td></tr>
<tr><td></td><td>Inception-v1</td><td>Image</td><td></td><td></td></tr>
<tr><td></td><td>GAN</td><td>Image</td><td></td><td></td></tr>
<tr><td>2012</td><td>AlexNet</td><td>Image</td><td></td><td>60M</td></tr>
<tr><td>1998</td><td>LeNet-5</td><td>Image</td><td></td><td>60K</td></tr>
<tr><td>?</td><td>Fast R-CNN</td><td></td><td>Object detection</td><td></td></tr>
<tr><td>?</td><td>Faster R-CNN</td><td></td><td>Object detection</td><td></td></tr>
<tr><td>?</td><td>CycleGAN</td><td></td><td>GAN</td><td></td></tr>
<tr><td>?</td><td>GauGAN</td><td></td><td>GAN</td><td></td></tr>
<tr><td>?</td><td>YOLO</td><td></td><td>Object detection</td><td></td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="prompt-engineering"><a class="header" href="#prompt-engineering">Prompt engineering</a></h1>
<ul>
<li>Retrieval-Augemented QA</li>
<li>PAL - (<a href="https://arxiv.org/pdf/2211.10435.pdf">Gao et al 2023</a>)</li>
<li>Self-Ask - (<a href="https://ofir.io/self-ask.pdf">Press et al 2022</a>)</li>
<li>Chain-of-Thought - (<a href="https://arxiv.org/abs/2201.11903">Wei et al 2022</a>)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="language"><a class="header" href="#language">Language</a></h1>
<ul>
<li><a href="language.html#vocabulary">Vocabulary</a></li>
<li><a href="language.html#concepts">Concepts</a></li>
<li><a href="language.html#tasks--applications">Tasks / applications</a></li>
<li><a href="language.html#data-types">Data types</a></li>
<li><a href="language.html#frameworks">Frameworks</a></li>
<li><a href="language.html#benchmarks">Benchmarks</a></li>
<li><a href="language.html#multimodal">Multimodal</a></li>
</ul>
<hr />
<p><a href="http://nlpprogress.com/">http://nlpprogress.com/</a></p>
<p>The field of designing methods and algorithms that take as input or produce as output unstructured human language.</p>
<p>Some characteristics of natural language are</p>
<ul>
<li>discrete / symbolic</li>
<li>compositional
<ul>
<li>letters form words, words form phrases and sentences, sentences form documents</li>
</ul>
</li>
</ul>
<h1 id="vocabulary"><a class="header" href="#vocabulary">Vocabulary</a></h1>
<p>Context = neighbouring words</p>
<p>Semantic = what this set of letters mean</p>
<p>Syntax = where does a word occur in a sentence, in relation to other words, related to grammar (conjugation, pluralise)</p>
<p>Vocabulary size = no. of unique words</p>
<p>Tokens = no. of words</p>
<p>Pivot word = current word</p>
<p>Context-dependent aspects of word meaning</p>
<p>Downstream task = supervised learning tasks that utilise a pre-trained model or component</p>
<p>Vocabulary size</p>
<p>Sequence length</p>
<p>Semantic questions:</p>
<ul>
<li>capital &amp; country</li>
<li>currency &amp; country</li>
<li>city &amp; state</li>
<li>man &amp; woman</li>
</ul>
<p>Syntax questions:</p>
<ul>
<li>adjective to adverb</li>
<li>opposite &gt;???</li>
<li>comparative</li>
<li>superlative</li>
<li>present participle</li>
<li>nationality adjective</li>
<li>past tense</li>
<li>plural nouns</li>
<li>plural verbs</li>
</ul>
<h1 id="concepts"><a class="header" href="#concepts">Concepts</a></h1>
<p>Ideas</p>
<ul>
<li>Language modelling
<ul>
<li>predict-the-next-word (vanilla)</li>
<li>cloze task (masked language modelling)</li>
<li>next-sentence prediction (next sentence prediction)</li>
<li>?? cloze task with permutations ?? (permutation language modelling)</li>
</ul>
</li>
<li>Modelling: architecture
<ul>
<li>RNN</li>
<li>Transformer</li>
<li>Autoregressive (sequential)</li>
<li>Decoder + encoder (autoencoder)</li>
<li>Bidirection</li>
<li>Sequence-to-sequence</li>
</ul>
</li>
<li>Modelling: components
<ul>
<li>Self-attention</li>
</ul>
</li>
<li>Modelling: algorithms (?)
<ul>
<li>
<p>Teacher forcing</p>
<p><img src="./teacher-forcing.jpg" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e9da026d-77dc-4e37-b5c1-413f2578f75a/Pasted_Graphic.jpg" /></p>
</li>
</ul>
</li>
</ul>
<h1 id="tasks--applications"><a class="header" href="#tasks--applications"><strong>Tasks / applications</strong></a></h1>
<ul>
<li>Level 1
<ul>
<li>
<p>POS tagging</p>
<p><img src="./pos-tagging.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ee861fec-710e-4134-bd32-28ce5958f065/Untitled.png" /></p>
</li>
<li>
<p>Constituency parsing</p>
<p>Break down a text into sub-phrases</p>
<p><img src="./constituency-parsing.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5ba43d9e-34ac-4351-b5b9-662edfe8902d/Untitled.png" /></p>
</li>
<li>
<p>Dependency parsing</p>
<p>Analyses the grammatical structure of a sentence, starting with the root. The word that has no dependency is called the root of the sentence. The verb is taken as the root of the sentence in most cases.</p>
<p><img src="./dependency-parsing.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8d157875-ccd7-476f-a2ac-1242aadb8317/Untitled.png" /></p>
</li>
<li>
<p>Semantic role labeling</p>
<p>Semantic role labelling assigns labels to words/phrases to indicate their semantic role in the sentence. Eg. &quot;agent&quot;, &quot;patient&quot;, &quot;instrument&quot;, &quot;manner&quot;.</p>
<p><img src="./semantic-role-labelling.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d8ec6b0c-bc88-4fe1-bf9a-e70feed5cc21/Untitled.png" /></p>
</li>
<li>
<p>Coreference resolution</p>
<p>Keep track of entities</p>
</li>
</ul>
</li>
</ul>
<hr />
<ul>
<li>Level 2
<ul>
<li>
<p>Text classification</p>
</li>
<li>
<p>Sentiment analysis</p>
<p>Classify emotions (positive or negative)</p>
</li>
<li>
<p>NER</p>
<p>Identify <em>named</em> entities (eg. people, location, organisation, number, product)</p>
</li>
<li>
<p><strong>Language modelling</strong></p>
</li>
<li>
<p>Semantic similarity</p>
</li>
<li>
<p>Text generation</p>
</li>
<li>
<p>Topic modelling</p>
</li>
<li>
<p>Keyword extraction</p>
</li>
<li>
<p>Event extraction</p>
</li>
<li>
<p>Relation extraction</p>
</li>
<li>
<p>Information extraction</p>
<p>Extracting structured information from unstructured data. Over the years, this task has been broken down into NER, coreference resolution, entity linking, relation extraction, even extraction etc.</p>
</li>
</ul>
</li>
</ul>
<hr />
<ul>
<li>Level 3
<ul>
<li>
<p>Summarisation</p>
</li>
<li>
<p>Machine translation</p>
</li>
<li>
<p>Open IE</p>
<p><a href="https://openie.allenai.org/">https://openie.allenai.org</a></p>
<p>Open Information Extraction. &quot;Open&quot; means any kind of relationships. This is in contrast to relation extraction where the relations do not need to be specified in advance.</p>
<pre><code>Born in a small town, she took the midnight train going anywhere.
</code></pre>
<ul>
<li>(<strong>born</strong>, she, in a small town)</li>
<li>(<strong>took</strong>, she, the midnight train going anywhere)</li>
<li>(<strong>going</strong>, the might train, anywhere)</li>
</ul>
<aside>
  💡 Why do we need this? The ability to glean facts and opinions from sentences.
</aside>
</li>
<li>
<p>Textual entailment</p>
<p>aka NLI (natural language inference)</p>
<p>Whether Sentence A (“<strong>premise</strong>”) can be implied or contradicted by Sentence B (“<strong>hypothesis</strong>”)</p>
<p>(SentenceA, SentenceB) → Entailment | Contradiction | Neutral</p>
<aside>
  💡 This problem is often considered an important test for the reasoning skills of ML systems
</aside>
</li>
<li>
<p>QA</p>
<p>AKA machine comprehension. QA answers natural language questions by selecting an answer span within an evidence text.</p>
<p><strong>Types of machine comprehension</strong></p>
<ul>
<li>Open-domain vs. closed-domain</li>
<li>Abstractive vs. Extractive</li>
<li>Factoid vs. Non-Factoid</li>
</ul>
</li>
<li>
<p>VQA</p>
<p>Visual question answering</p>
<p><a href="https://visualqa.org/">https://visualqa.org</a></p>
</li>
<li>
<p>Image captioning</p>
</li>
<li>
<p>Chitchat dialogue</p>
</li>
<li>
<p>Paraphrasing</p>
</li>
</ul>
</li>
</ul>
<hr />
<p><img src="./nlp-task-spectrum.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dd6f8e6a-90e2-485e-9e90-d81e98967e29/Untitled.png" /></p>
<h1 id="data-types"><a class="header" href="#data-types"><strong>Data types</strong></a></h1>
<ul>
<li>Text</li>
<li>Parallel corpus</li>
<li>Documents</li>
<li>Text with labels</li>
</ul>
<h1 id="frameworks"><a class="header" href="#frameworks"><strong>Frameworks</strong></a></h1>
<ul>
<li>
<p>fairseq</p>
</li>
<li>
<p><a href="https://nlp.stanford.edu/software/lex-parser.shtml#Download">Stanford</a></p>
</li>
<li>
<p>spacy.io</p>
</li>
<li>
<p><a href="https://explosion.ai/demos/displacy-ent">https://explosion.ai/demos/displacy-ent</a></p>
</li>
<li>
<p>Neuralcoref</p>
</li>
<li>
<p><a href="https://fasttext.cc/">https://fasttext.cc</a></p>
</li>
<li>
<p><a href="http://allennlp.org/">allennlp.org</a></p>
</li>
<li>
<p>NLTK</p>
</li>
<li>
<p>gensim</p>
</li>
<li>
<p>TensorFlow</p>
</li>
<li>
<p>Universal Language Model Fine-tuning (ULMFiT) for trf learning</p>
</li>
<li>
<p><a href="https://github.com/deepset-ai/FARM">https://github.com/deepset-ai/FARM</a></p>
</li>
<li>
<p><a href="https://github.com/OpenNMT/OpenNMT-tf">https://github.com/OpenNMT/OpenNMT-tf</a></p>
</li>
<li>
<p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
</li>
<li>
<p><a href="https://github.com/huggingface/transformers">huggingface / transformers</a></p>
</li>
<li>
<p>compromise.cool</p>
</li>
<li>
<p><a href="https://github.com/abelriboulot/onnxt5">ONNXT5</a> inference-ready</p>
<p><code>question: ... ? context: ...</code></p>
<p><code>summarize: ...</code></p>
<p><code>translate english to french: ...</code></p>
</li>
<li>
<p><a href="https://www.sbert.net/index.html">https://www.sbert.net/index.html</a></p>
</li>
</ul>
<h1 id="benchmarks"><a class="header" href="#benchmarks"><strong>Benchmarks</strong></a></h1>
<p>GLUE score (General Language Understanding Evaluation)</p>
<p>ROUGE (recall-oriented understudy for gisting evaluation)</p>
<p>SuperGLUE</p>
<p>XGLUE</p>
<h1 id="multimodal"><a class="header" href="#multimodal">Multimodal</a></h1>
<ul>
<li>Text</li>
<li>Tabular</li>
<li>Vision</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="processing"><a class="header" href="#processing">Processing</a></h1>
<h1 id="preprocessing-i"><a class="header" href="#preprocessing-i"><strong>Preprocessing I</strong></a></h1>
<ul>
<li>Remove stop words</li>
<li>Lowercase the text</li>
<li>Strip punctuations</li>
</ul>
<h1 id="preprocessing-ii"><a class="header" href="#preprocessing-ii"><strong>Preprocessing II</strong></a></h1>
<ul>
<li>Word tokenisation</li>
<li>Lemmatisation</li>
<li>Stemming</li>
<li>Sentence segmentation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tokenisatin"><a class="header" href="#tokenisatin">Tokenisatin</a></h1>
<p>Token: ‘smallest unit of language in the eyes of computer’. Tokenisation is especially useful in agglutinative languages like Turkish.</p>
<h3 id="algorithms"><a class="header" href="#algorithms">Algorithms</a></h3>
<ul>
<li>Character</li>
<li>Subword
<ul>
<li>BPE (Byte-Pair Encoding). By frequency. Implementations: SentencePiece, fastBPE.</li>
<li>WordPiece. By likelihood</li>
<li>Unigram Language Model</li>
<li>Syllable tokenisation</li>
<li>Character n-grams (by fasttext)</li>
<li><a href="https://github.com/rsennrich/subword-nmt">rsennrich / subword-nmt</a></li>
</ul>
</li>
<li>Word
<ul>
<li><a href="https://spacy.io/">spaCy</a></li>
<li><a href="http://www.statmt.org/moses/?n=Development.GetStarted">Moses</a></li>
</ul>
</li>
</ul>
<p>Libraries</p>
<ul>
<li>Moses</li>
<li>Whitespace</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="embeddings"><a class="header" href="#embeddings">Embeddings</a></h1>
<p>“Representation Learning”</p>
<p>Represent how something functions syntactically (position) and semantically (meaning) + relationships</p>
<p>How to generate a numerical representation of the tokens? Need to train with some data so that model understands the world</p>
<h2 id="character"><a class="header" href="#character">Character</a></h2>
<ul>
<li>CNN</li>
</ul>
<h2 id="subword"><a class="header" href="#subword">Subword</a></h2>
<ul>
<li>WordPiece</li>
<li>Unigram Language Model</li>
<li>MOE (Misspelling Oblivious Embeddings)</li>
<li>BPEmb (<a href="https://github.com/VKCOM/YouTokenToMe">https://github.com/VKCOM/YouTokenToMe</a>)</li>
<li>sentencepiece (<a href="https://github.com/google/sentencepiece">google / sentencepiece</a>)</li>
</ul>
<h2 id="word"><a class="header" href="#word">Word</a></h2>
<ul>
<li>Bag-of-words</li>
<li>TF-IDF</li>
<li>Gensim’s Word2Vec</li>
<li>NNLM (Neural Network Language Model)</li>
<li>Word2Vec
<ul>
<li>Skip-Gram. word and phrase representations learned by Skip-gram model exhibits a linear structure that makes it possible to perform precise analogical reasoning using simple vector arithmetics</li>
<li>CBOW</li>
</ul>
</li>
<li>GLoVe</li>
<li>ELMo
<ul>
<li>Contextual: The representation for each word depends on the entire context in which it is used.</li>
<li>Deep: The word representations combine all layers of a deep pre-trained neural network.</li>
<li>Character based: ELMo representations are purely character based, allowing the network to use morphological clues to form robust representations for out-of-vocabulary tokens unseen in training.</li>
</ul>
</li>
<li>LDA</li>
<li>fastText</li>
<li>MUSE (Multilingual Unsupervised or Supervised word Embeddings)</li>
</ul>
<h2 id="sentence"><a class="header" href="#sentence">Sentence</a></h2>
<ul>
<li>USE (multilingual)</li>
<li>InferSent</li>
<li>SentenceBERT</li>
<li><a href="https://github.com/facebookresearch/LASER">LASER</a>
Language-Agnostic SEntence Representations. Trained on 90+ languages. Model has the ability to accept code-switching!</li>
<li>LaBSE</li>
</ul>
<h2 id="document"><a class="header" href="#document">Document</a></h2>
<ul>
<li>Doc2Vec</li>
<li>Bag-of-words</li>
<li>TF-IDF</li>
</ul>
<h1 id="summary"><a class="header" href="#summary">Summary</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Model</th><th>Encoding</th><th>Characteristics</th><th>Optimiser</th><th>Word-to-embedding</th><th>Available modules trained on</th><th>Getting embeddings</th></tr></thead><tbody>
<tr><td>NNLM</td><td></td><td>MLP with projection layer and hidden layer</td><td></td><td></td><td></td><td></td></tr>
<tr><td>Skip-gram</td><td>One-hot encoding of words</td><td>MLP with projection layer</td><td>Gradient descent</td><td>1-to-1</td><td>Wikipedia English</td><td>Output</td></tr>
<tr><td>GloVe</td><td>Co-occurrence matrix</td><td>SVD-like</td><td>Gradient descent</td><td>1-to-1</td><td></td><td>Output</td></tr>
<tr><td>fastText</td><td>Character-level (subword).Character n-grams</td><td></td><td></td><td></td><td></td><td>?</td></tr>
<tr><td>ELMo</td><td>Character-level CNN (subword)</td><td>Bi-directional, LM</td><td>Gradient descent</td><td>1-to-many</td><td>5.5B tokens from Wikipedia 1.9B</td><td>Aggregate output layers</td></tr>
<tr><td>Transformer</td><td></td><td>Self-attention, seq2seq</td><td></td><td></td><td></td><td>?</td></tr>
<tr><td>BERT</td><td></td><td>LM, transformer</td><td></td><td></td><td></td><td>Aggregate encoder stack layers</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="encoding"><a class="header" href="#encoding">Encoding</a></h1>
<h3 id="how-to-encode-a"><a class="header" href="#how-to-encode-a">How to encode a...?</a></h3>
<ul>
<li>
<p>Token</p>
<ul>
<li>One-hot</li>
<li>Bag-of-x</li>
<li>Aggregate of x (concat, sum)</li>
</ul>
</li>
<li>
<p>Position</p>
<ul>
<li>absolute positional embedding</li>
<li>relative position embeddings</li>
<li>sinusoidal positional embedding</li>
</ul>
<p><img src="./positional-encoding.jpg" alt="Positional encoding" /></p>
</li>
</ul>
<ul>
<li>RoPE -- Rotary positional embedding</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="representation"><a class="header" href="#representation">Representation</a></h1>
<h2 id="sparse-representations"><a class="header" href="#sparse-representations"><strong>Sparse Representations</strong></a></h2>
<p>sparsity problem</p>
<p>no similarity</p>
<ul>
<li>One-hot encoding (1-of-V coding)</li>
<li>Multi-hot encoding</li>
</ul>
<h2 id="traditional"><a class="header" href="#traditional"><strong>Traditional</strong></a></h2>
<ul>
<li>n-gram</li>
<li>Bag of words</li>
</ul>
<h2 id="denser-representations-embedding--embedding-vector--vector-representation--word-representations-in-vector-space"><a class="header" href="#denser-representations-embedding--embedding-vector--vector-representation--word-representations-in-vector-space"><strong>Denser Representations: Embedding / embedding vector / vector representation / word representations in vector space</strong></a></h2>
<p>learned lookup table</p>
<p>idea: every word is represented by a vector</p>
<h2 id="embeddings-frequency-based"><a class="header" href="#embeddings-frequency-based">Embeddings: <strong>Frequency-based</strong></a></h2>
<ul>
<li><strong>Count Vectors</strong></li>
<li><strong>TF-IDF</strong> (term frequency - inverse document frequency)</li>
<li><strong>Co-occurence matrix</strong></li>
</ul>
<h2 id="embeddings-prediction-based"><a class="header" href="#embeddings-prediction-based">E<strong>mbeddings: Prediction-based</strong></a></h2>
<ul>
<li><strong>Skip-gram</strong>: learning embeddings by predicting word contexts</li>
<li><strong>CBOW</strong></li>
<li><strong>fastText</strong>: robust embeddings using subword information</li>
<li><strong>GloVe</strong>: learning embeddings of size 100 from word co-occurrence (Global Vectors for Word Representation)</li>
<li><strong>ELMo</strong>: Embeddings from Language Models (pre-trained)</li>
<li>PPMI matrix decomposition (using SVD) to get word embeddings</li>
<li>Skip-Thought Vectors</li>
<li>Doc2Vec</li>
<li>USE (universal sentence encoder)</li>
<li>NNLM (neural network language model)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="language-modelling"><a class="header" href="#language-modelling">Language modelling</a></h1>
<p>Difference between encoder and language model is that encoders output a vector whereas LMs output a sequence of tokens. </p>
<p><a href="https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf">https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf</a></p>
<p><a href="https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html#gpt-2">https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html</a></p>
<p><a href="https://syncedreview.com/2017/09/10/language-model-a-survey-of-the-state-of-the-art-technology/">https://syncedreview.com/2017/09/10/language-model-a-survey-of-the-state-of-the-art-technology/</a></p>
<hr />
<ul>
<li><a href="language-modelling.html#why-model-language">Why model language?</a></li>
<li><a href="language-modelling.html#types-of-language-models">Types of language models</a></li>
<li><a href="language-modelling.html#statistical-language-model">Statistical language model</a>
<ul>
<li><a href="language-modelling.html#model">Model</a></li>
<li><a href="language-modelling.html#markov-assumption-as-approximation">Markov assumption as approximation</a></li>
<li><a href="language-modelling.html#solution-to-optimisation-problem">Solution to optimisation problem</a></li>
<li><a href="language-modelling.html#tweaks">Tweaks</a></li>
<li><a href="language-modelling.html#problems">Problems</a></li>
</ul>
</li>
<li><a href="language-modelling.html#neural-language-models">Neural language models</a>
<ul>
<li><a href="language-modelling.html#model-1">Model</a></li>
<li><a href="language-modelling.html#architectures">Architectures</a></li>
</ul>
</li>
<li><a href="language-modelling.html#how">How?</a>
<ul>
<li><a href="language-modelling.html#1-teach-the-model-the-world-pre-training">1. Teach the model the world (&quot;pre-training&quot;)</a></li>
<li><a href="language-modelling.html#2-applying--fine-tune--datasets--downstream-tasks--see-how-well-you-trained-the-model">2. Applying / Fine-tune / datasets / downstream tasks / see how well you trained the model</a></li>
</ul>
</li>
<li><a href="language-modelling.html#types-of-fine-tuning">Types of fine tuning</a></li>
<li><a href="language-modelling.html#what-did-we-learn">What did we learn?</a></li>
</ul>
<hr />
<h1 id="why-model-language"><a class="header" href="#why-model-language">Why model language?</a></h1>
<p>Natural language is not deterministic unlike programming language. This randomness in the sequence of words can be modelled probabilistically. </p>
<h1 id="types-of-language-models"><a class="header" href="#types-of-language-models">Types of language models</a></h1>
<ul>
<li>Statistical language model (count-based)</li>
<li>Neural language model (continuous-based)</li>
</ul>
<h1 id="statistical-language-model"><a class="header" href="#statistical-language-model">Statistical language model</a></h1>
<h2 id="model"><a class="header" href="#model">Model</a></h2>
<p>We first fix $n$ to be the length of this sequence of words. A language model is the (joint) probability distribution over a sequence of words</p>
<p>$$
p(w_1, w_2, ..., w_n)
$$</p>
<p>where $w$ is any word available in the language's vocabulary and $\theta$ are the parameters of the model and which can be conveniently broken down into</p>
<p>$$
p(w_n|w_{n-1}, w_{n-2}, ...,w_1) \times ... \times p(w_3|w_2,w_1) \times p(w_2|w_1) \times p(w_1) =\prod_i p(w_i|w_{i-1}, ..., w_1)
$$</p>
<p>or (for better readability)</p>
<p>$$
p(w_1) \times p(w_2|w_1) \times p(w_3|w_2,w_1) \times ... \times p(w_n|w_{n-1}, w_{n-2}, ...,w_1)
$$</p>
<p>The way we model language is that the choice of the next word (&quot;<strong>next-word prediction</strong>&quot;) depends on the previous words which have said (&quot;realise&quot;).</p>
<p>Now let's compute the joint probability </p>
<p>$$
p(\text{its}, \text{water}, \text{is}, \text{so}, \text{transparent}, \text{that})
$$</p>
<p>or rather let's try to predict the next word, say finding out if the next word is the:</p>
<p>$$
p(\text{the} | \text{its}, \text{water}, \text{is}, \text{so}, \text{transparent}, \text{that})
$$</p>
<p>which equals to (by Bayes):</p>
<p>$$
\frac{
p(\text{its}, \text{water}, \text{is}, \text{so}, \text{transparent}, \text{that}, \text{the})
}{p(\text{its}, \text{water}, \text{is}, \text{so}, \text{transparent}, \text{that})}
$$</p>
<p>We could take the counts based on our data:</p>
<p>$$
\frac{
Count(\text{its}, \text{water}, \text{is}, \text{so}, \text{transparent}, \text{that}, \text{the})
}{Count(\text{its}, \text{water}, \text{is}, \text{so}, \text{transparent}, \text{that})}
$$</p>
<p>But this is impossible</p>
<aside>
💡 Why ah? Because if they don't exist in our data, doesn't mean they don't occur naturally.
</aside>
<h2 id="markov-assumption-as-approximation"><a class="header" href="#markov-assumption-as-approximation">Markov assumption as approximation</a></h2>
<p>In the $n$-th order Markovian assumption, we assume the next word depends on the last $n$ words.</p>
<p>We simplify the problem to instead find (&quot;<strong>bigram model</strong>&quot;)</p>
<p>$$
p(\text{the} |  \text{that})
$$</p>
<p>or (&quot;<strong>trigram model</strong>&quot;)</p>
<p>$$
p(\text{the} | \text{transparent}, \text{that})
$$</p>
<p>or</p>
<p>$$
p(\text{the} | \text{so}, \text{transparent}, \text{that})
$$</p>
<p>or to generalise, we simplify the problem to be</p>
<p>$$
p(w_1, w_2, ..., w_n) \approx \prod_i p(w_i|w_{i-k}, w_{i-k-1}, ..., w_{i-1})
$$</p>
<p>where $k$ is the number of preceding words before $w_i$. Another way to look at this is:</p>
<p>$$
p(w_i| w_1, w_2,  ..., w_{i-1}) \approx \prod_i p(w_i|w_{i-k}, w_{i-k-1}, ..., w_{i-1})
$$</p>
<p>The value $k$ then represents if its a unigram model ($k=0$), bigram ($k=1$) or $n$-gram.</p>
<h2 id="solution-to-optimisation-problem"><a class="header" href="#solution-to-optimisation-problem">Solution to optimisation problem</a></h2>
<p>A common solution is to use MLE. Below is for a bigram model.</p>
<p>$$
p(w_i|w_{i-1})=\frac{count(w_{i-1}, w_i)}{count(w_{i-1})}
$$</p>
<h2 id="tweaks"><a class="header" href="#tweaks">Tweaks</a></h2>
<ul>
<li>Laplace smoothing (for unseen words)</li>
</ul>
<h2 id="problems"><a class="header" href="#problems">Problems</a></h2>
<ul>
<li>Sparsity</li>
<li>Curse of dimensionality</li>
</ul>
<h1 id="neural-language-models"><a class="header" href="#neural-language-models">Neural language models</a></h1>
<h2 id="model-1"><a class="header" href="#model-1">Model</a></h2>
<p>$$
p(\text{word}|&lt;k \text{ previous words}&gt;, \theta_{model})
$$</p>
<h2 id="architectures"><a class="header" href="#architectures">Architectures</a></h2>
<ul>
<li>
<p>FFNN</p>
</li>
<li>
<p>RNN</p>
</li>
<li>
<p>Transformers</p>
<p>The key/value/query concepts come from retrieval systems. For example, when you type a query to search for some video on Youtube, the search engine will map your query against a set of keys (video title, description etc.) associated with candidate videos in the database, then present you the best matched videos (values). <a href="https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms/424127#424127">Source</a></p>
</li>
</ul>
<h1 id="how"><a class="header" href="#how">How?</a></h1>
<ol>
<li>
<p>Pre-train, framed as a language modelling</p>
<p>Pretraining is usually down on a huge corpus.</p>
</li>
<li>
<p>Applying to downstream tasks:</p>
<ol>
<li>Fine-tune (specialise), framed as predicting conditional probabilities
<ul>
<li>Discriminative tasks</li>
<li>Generative tasks</li>
<li>Abstractive tasks</li>
</ul>
</li>
<li>Feature-based tasks</li>
</ol>
</li>
</ol>
<h2 id="1-teach-the-model-the-world-pre-training"><a class="header" href="#1-teach-the-model-the-world-pre-training">1. Teach the model the world (&quot;pre-training&quot;)</a></h2>
<p>A language model is the statistical model that...</p>
<ul>
<li>
<p>Native language</p>
<ul>
<li>
<p>What's the next word? What are the next words? (&quot;<strong>causal language modelling</strong>&quot; / &quot;<strong>next-token prediction</strong>&quot;)</p>
<p>GPT, GPT2, GPT3, CTRL, Transformer-XL, Reformer, XLNet, ProphetNet</p>
</li>
<li>
<p>Cloze (&quot;<strong>masked language modelling</strong>&quot;). Predict only the masked words.</p>
<p>BERT</p>
</li>
<li>
<p>Can this be the next sentence? What could be the next sentence? (&quot;<strong>next sentence prediction</strong>&quot;) (CLM?)</p>
<p>BERT</p>
</li>
</ul>
<hr />
<ul>
<li>
<p>Were these 2 sentences swapped? If swapped, can I still figure out the context? (&quot;<strong>sentence ordering prediction</strong>&quot;)</p>
</li>
<li>
<p>Define what task I want to do, then work on it (&quot;<strong>instructional language modelling</strong>&quot;)</p>
<p>CTRL, T5, GPT3?</p>
</li>
<li>
<p>Correct my sentence. Which words did I miss out? (&quot;<strong>correctional language modelling</strong>&quot;)</p>
</li>
<li>
<p>Summarise the content (&quot;<strong>summarisational</strong>&quot;)</p>
<ul>
<li>Mask a span of tokens as a single mask token</li>
<li>GSG (Pegasus)</li>
</ul>
</li>
<li>
<p>Downstream tasks (&quot;<strong>fine-tuning</strong>&quot;)</p>
</li>
</ul>
<hr />
<ul>
<li>
<p>Which words were replaced? Which words are &quot;natural&quot; to you? (&quot;<strong>adversarial language modelling</strong>&quot;)</p>
</li>
<li>
<p>Learning with images and sounds etc. (&quot;<strong>multimodal</strong>&quot;)</p>
</li>
<li>
<p>Understanding the context</p>
<p>XLNet</p>
</li>
<li>
<p>Reading / understanding <em>long</em> texts (&quot;<strong>high attention</strong>&quot;)</p>
<p>Transformer-XL, Longformer</p>
</li>
<li>
<p>Factual language modelling</p>
</li>
</ul>
</li>
<li>
<p>Learning a new language (&quot;<strong>cross-language modelling</strong>&quot; / &quot;<strong>translation language modelling</strong>&quot;)</p>
<ul>
<li>(SentenceInLanguageA, SentenceInLanguageB)</li>
</ul>
</li>
</ul>
<p>What is the model built for?</p>
<ul>
<li>Generate only (decoder? only, autoregressive). Eg. generate text</li>
<li>Understand (autoencoder) and possibly use it for something useful next time. Eg. Sentence classification.</li>
<li>Understand and generate (sequence-to-sequence). Eg. translation, summarisation</li>
</ul>
<p>Data sources:</p>
<p>Common sources are Wikipedia, web news, web question-answer pages and discussion forums.</p>
<h2 id="2-applying--fine-tune--datasets--downstream-tasks--see-how-well-you-trained-the-model"><a class="header" href="#2-applying--fine-tune--datasets--downstream-tasks--see-how-well-you-trained-the-model">2. Applying / Fine-tune / datasets / downstream tasks / see how well you trained the model</a></h2>
<p>(SuperGLUE tasks)</p>
<ul>
<li>
<p>Discriminative tasks</p>
<p>Grammar</p>
<ul>
<li>CoLA (GLUE)</li>
</ul>
<p>Sentiment analysis</p>
<ul>
<li>SST-2 (GLUE)</li>
</ul>
</li>
<li>
<p>Generative tasks</p>
<ul>
<li>Summarisation
<ul>
<li>ELI5</li>
<li>XSum</li>
<li>ConvAI2</li>
<li>CNN/DM</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Unclassified</p>
<ul>
<li>Sentence similarity / paraphrase
<ul>
<li>STS-B (GLUE)</li>
<li>QQP (GLUE)</li>
</ul>
</li>
<li>Question answering
<ul>
<li>SQuAD</li>
<li>QNLI (GLUE)</li>
</ul>
</li>
<li>Textual entailment
<ul>
<li>MNLI (GLUE)</li>
</ul>
</li>
<li>Translation
<ul>
<li>WMT</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Speed</p>
<p>Reformer</p>
<ul>
<li>
<p>Continual learning</p>
</li>
<li>
<p>Understanding the context first (dual encoder, one decoder)</p>
</li>
<li>
<p>Lack of information (data)</p>
</li>
<li>
<p>Causal language modelling</p>
<p>AKA next-word prediction, next-token prediction</p>
</li>
<li>
<p>Mask language modelling</p>
<ol>
<li>Randomly mask 15% of input tokens</li>
<li>Model to predict the masked tokens</li>
</ol>
</li>
<li>
<p>Next-sentence prediction</p>
<p>Ever example is a tuple of</p>
<p>((Sentence A, Sentence B), B is next | B is not next)</p>
</li>
</ul>
<p><img src="./model-summary.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b18fe357-dd96-4941-b867-704842736e52/Untitled.png" /></p>
<p><a href="https://huggingface.co/transformers/model_summary.html">https://huggingface.co/transformers/model_summary.html</a></p>
<p>This categorisation is based on the question &quot;how do you train/teach these models?&quot; Note that it does not mean that they do not share the same architecture.</p>
<h1 id="types-of-fine-tuning"><a class="header" href="#types-of-fine-tuning">Types of fine tuning</a></h1>
<p><a href="https://ruder.io/recent-advances-lm-fine-tuning/">https://ruder.io/recent-advances-lm-fine-tuning/</a></p>
<ul>
<li><strong>Adaptive fine-tuning</strong> — specialise to target domain
<ol>
<li>Pre-training</li>
<li>Adaptive fine-tuning on target data</li>
<li>Fine-tuning on task labels</li>
</ol>
</li>
<li><strong>Behavioural fine-tuning</strong> — specialise to target task
<ol>
<li>Pre-training</li>
<li>Behavioural fine-tuning on relevant tasks</li>
<li>Fine-tuning on task labels</li>
</ol>
</li>
<li><strong>Parameter-efficient fine-tuning</strong> — reduce model size</li>
<li><strong>Text-to-text fine-tuning</strong> — ?</li>
</ul>
<h1 id="what-did-we-learn"><a class="header" href="#what-did-we-learn">What did we learn?</a></h1>
<ul>
<li>Pretraining, then fine tuning</li>
<li>MLM</li>
<li>More data is good</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="topic-modelling"><a class="header" href="#topic-modelling">Topic modelling</a></h1>
<p>Resources</p>
<p>BERT-based: <a href="https://github.com/MaartenGr/KeyBERT/">https://github.com/MaartenGr/KeyBERT/</a></p>
<p><a href="https://github.com/boudinfl/pke">https://github.com/boudinfl/pke</a></p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Need more than 1 doc</th><th>Algorithm</th><th>Output: Doc-Topic</th><th>Output: Term-Doc</th><th>Output: Term-Topic</th><th>Output: similarity matrix</th></tr></thead><tbody>
<tr><td>TF-IDF</td><td>✓</td><td>Frequency-based</td><td></td><td>✓</td><td></td><td></td></tr>
<tr><td>NMF</td><td>✓</td><td>SVD of term-docV = WH</td><td>✓</td><td></td><td>✓</td><td></td></tr>
<tr><td>LDA</td><td>✓</td><td>Probabilistic generative modelling</td><td>✓</td><td></td><td>✓</td><td></td></tr>
<tr><td>LSA</td><td>✓</td><td>SVD of term-docX = UΣVT</td><td></td><td>✓</td><td>✓</td><td></td></tr>
<tr><td>RAKE</td><td></td><td>Word co-occurrences, scoring system</td><td></td><td></td><td></td><td></td></tr>
<tr><td>TextRank</td><td></td><td>Similarity (word co-occurrences)</td><td></td><td></td><td></td><td>✓</td></tr>
<tr><td>Bag of words</td><td></td><td>Word frequency</td><td></td><td></td><td></td><td></td></tr>
<tr><td>POS tagging</td><td></td><td>Linguistic approach</td><td></td><td></td><td></td><td></td></tr>
<tr><td>NER tagging</td><td></td><td>Linguistic approach</td><td></td><td></td><td></td><td></td></tr>
<tr><td>Random Projections</td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
</div>
<p><strong>Theory</strong></p>
<p>Distributional hypothesis - The <strong>distributional hypothesis</strong> in linguistics is derived from the semantic theory of language usage, i.e. words that are used and occur in the same contexts tend to purport similar meanings</p>
<p>Semantic similarity</p>
<p>Vector space model - representing text documents as vectors</p>
<hr />
<h1 id="tf-idf"><a class="header" href="#tf-idf"><strong>TF-IDF</strong></a></h1>
<p>(Term Frequency - Inverse Document Frequency)</p>
<p>words which are rare are the ones that actually help in distinguishing between the data, and carry more weight</p>
<ol>
<li>Get a list of unique words.</li>
<li>For every word in every document, calculate
<ul>
<li>$$tf = \frac{\text{count of this term}}{\text{total no. of words}}$$</li>
<li>$$ idf = \log \frac{\text{total no. of docs}}{\text{no. of docs with this term}}$$</li>
<li>$$tfidf = tf \times df$$</li>
</ul>
</li>
</ol>
<p>Document A: The car is driven on the road.</p>
<p>Document B: The truck is driven on the highway.</p>
<p><img src="./tf-idf.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b1103cc7-0688-4750-912d-d811e7e8de31/log(22)__0.png" /></p>
<h1 id="nmf"><a class="header" href="#nmf"><strong>NMF</strong></a></h1>
<p>(Nonnegative Matrix Factorisation)</p>
<h1 id="glove"><a class="header" href="#glove"><strong>GloVe</strong></a></h1>
<ul>
<li>svd</li>
</ul>
<h1 id="rake"><a class="header" href="#rake"><strong>RAKE</strong></a></h1>
<p>(Rapid Automation Keyword Extraction)</p>
<ol>
<li>Get tokens by partitioning using stop words and punctuation marks</li>
<li>Get co-occurrence matrix</li>
<li>Simple scoring
Degree(“keyword”) = sum of no. of co-occurrences = 3+3+1+1
Frequency(“keyword”) = cell entry in co-occurrence = 3
Score(“keyword”) = degree/frequency
<img src="./rake.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/73abfb6b-f8c5-44fc-b26d-05d44bcc111f/keyword.png" /></li>
</ol>
<h1 id="lda"><a class="header" href="#lda"><strong>LDA</strong></a></h1>
<p>(Latent Dirichlet Allocation)</p>
<ul>
<li>Model the data as observations that arise from a generative probabilistic process that includes hidden variables (topics/themes)</li>
<li>Infer the hidden structure using posterior inference</li>
</ul>
<h1 id="textrank"><a class="header" href="#textrank"><strong>TextRank</strong></a></h1>
<p>Inspired from PageRank</p>
<p>Construct a (cosine) similarity matrix by comparing their <strong>vector representations</strong> (summing/average of all word embeddings in every sentence).</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>Sentence1</th><th>Sentence2</th><th>Sentence3</th></tr></thead><tbody>
<tr><td>Sentence1</td><td></td><td></td><td></td></tr>
<tr><td>Sentence2</td><td></td><td></td><td></td></tr>
<tr><td>Sentence3</td><td></td><td></td><td></td></tr>
</tbody></table>
</div>
<p>Construct a (cosine) similarity matrix by comparing their <strong>vector representations</strong> or other word occurrences methods.</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>Word1</th><th>Word2</th><th>Word3</th></tr></thead><tbody>
<tr><td>Word1</td><td></td><td></td><td></td></tr>
<tr><td>Word2</td><td></td><td></td><td></td></tr>
<tr><td>Word3</td><td></td><td></td><td></td></tr>
</tbody></table>
</div>
<p>Lastly, rank.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sequence-modelling"><a class="header" href="#sequence-modelling">Sequence modelling</a></h1>
<ul>
<li><a href="sequence-modelling.html#motivation">Motivation</a></li>
<li><a href="sequence-modelling.html#sequence-modelling-design-criteria">Sequence modelling design criteria</a></li>
<li><a href="sequence-modelling.html#backpropagation-through-time">Backpropagation through time</a></li>
<li><a href="sequence-modelling.html#lstms-and-grus">LSTMs and GRUs</a></li>
<li><a href="sequence-modelling.html#attention">Attention</a></li>
</ul>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>Bag-of-words has no order</p>
<h2 id="sequence-modelling-design-criteria"><a class="header" href="#sequence-modelling-design-criteria">Sequence modelling design criteria</a></h2>
<p>The model must be able to</p>
<ul>
<li>Handle variable-length sequence</li>
<li>Maintain information about the order</li>
<li>Share parameters across the sequence</li>
<li>Track long-term dependencies</li>
</ul>
<h2 id="backpropagation-through-time"><a class="header" href="#backpropagation-through-time">Backpropagation through time</a></h2>
<p>Backpropagation through time involves many multiplication of the weight matrices and gradient such that</p>
<ul>
<li>Many values &gt; 1: exploding gradients</li>
</ul>
<p>Gradient clipping</p>
<ul>
<li>Many values &lt; 1: vanishing gradients</li>
</ul>
<p>Activation function - use ReLU</p>
<p>Weight initialisation - weights to Identity matrix ?, bias to zero</p>
<p>Network architecture - gates cells</p>
<h2 id="lstms-and-grus"><a class="header" href="#lstms-and-grus">LSTMs and GRUs</a></h2>
<p>Information is added or removed through structures called gates.</p>
<ol>
<li>Forget</li>
<li>Store</li>
<li>Update</li>
<li>Output</li>
</ol>
<p><img src="./rnn-gru-lstm.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/93cae719-3dcc-4f3b-9b3d-b9504524e787/Untitled.png" /></p>
<h2 id="attention"><a class="header" href="#attention">Attention</a></h2>
<p>Decoder has access to all the states in the encoder. Network places attention on different parts of the input sentence.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summarisation"><a class="header" href="#summarisation">Summarisation</a></h1>
<h1 id="benchmark"><a class="header" href="#benchmark">Benchmark</a></h1>
<p>GigaWord benchmark; ROUGE-1, ROUGE-2, ROUGE-L</p>
<p><a href="https://paperswithcode.com/sota/text-summarization-on-gigaword">https://paperswithcode.com/sota/text-summarization-on-gigaword</a></p>
<h1 id="types"><a class="header" href="#types">Types</a></h1>
<ul>
<li>Extractive: identify important sentences and reproduce verbatim</li>
<li>Abstractive: interpret text and generate new summary text</li>
</ul>
<p>Extractive</p>
<ol>
<li>Construct an intermediate representation</li>
<li>Score the sentences</li>
<li>Select top k</li>
</ol>
<p>(<a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a>)</p>
<h1 id="rouge-scoring"><a class="header" href="#rouge-scoring">ROUGE scoring</a></h1>
<p>Recall-Oriented Understudy fo Gisting Evaluation</p>
<p>(Works only for extractive summaries?)</p>
<pre><code>**SYS**
the cat was found under the bed

**REF**
the cat was       under the bed
</code></pre>
<p>$$
\text{ROUGE-1} = \frac{6}{6}
$$</p>
<p>$$
\text{ROUGE-1}_{Precision} = \frac{6}{7}
$$</p>
<pre><code>**SYS**
the cat, cat was, **was found, found under,** under the, the bed

**REF**
the cat, cat was,       **was under,**        under the, the bed
</code></pre>
<p>$$
\text{ROUGE-2} = \frac{4}{5}
$$</p>
<p>$$
\text{ROUGE-2}_{Precision} = \frac{4}{6}
$$</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="machine-translation"><a class="header" href="#machine-translation">Machine translation</a></h1>
<h1 id="terminologies"><a class="header" href="#terminologies">Terminologies</a></h1>
<p>Source language</p>
<p>Target language</p>
<p>parallel corpus / bi texts - a pair of texts such that one is a translation of the other</p>
<p>Deceptive cognates</p>
<p>Syntactic duplicates</p>
<p>Morphology - analysis of structure of words</p>
<p>Syntax - analysis of structure of sentence</p>
<p>Syntactic analysis - an analysis of the relative grammatical function of different words in the sentence</p>
<p>Lemma - dictionary form</p>
<p>Word sense - no of meanings per word</p>
<p>“Stemming” - get pseudo roots (Porter stemming, 1980)</p>
<p>pivot language - an intermediate natural language</p>
<p>interlingua - an artificial language with abstract representation</p>
<p>polysemy - coexistence of many possible meanings for a word/phrase</p>
<p>sentence alignment</p>
<p><img src="./machine-translation-1.jpg" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c5e95722-0bab-474c-b5ed-90637c16914d/8_13_12_7_1.jpg" /></p>
<h1 id="theories"><a class="header" href="#theories">Theories</a></h1>
<ul>
<li>Meaning is not formally defined but corresponds to the way words are used</li>
<li>It should respect the main characteristics of the original text, the tone and style, details of its ideas, overall structure</li>
</ul>
<h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<p>The chicken is ready to eat</p>
<p>There was not a single man at the party</p>
<h1 id="history"><a class="header" href="#history">History</a></h1>
<p>Rule-Based</p>
<ul>
<li>direct translation system</li>
<li>transfer system</li>
<li>interlingua</li>
</ul>
<p>1940s - idea of autatic translation</p>
<p>1940s-1960s - advent of computers. naive approaches</p>
<p>1965-1990 nothing afterv alpac report</p>
<p>1990s - Statistical Machine Translation</p>
<p>2014 - Neural Machine Translation</p>
<h1 id="example-based-translation"><a class="header" href="#example-based-translation"><strong>Example-based translation</strong></a></h1>
<p>translation by analogy</p>
<p>translate: training is not the solution to every problem</p>
<p><img src="./machine-translation-2.jpg" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/73eb64d5-41fa-41ba-bffd-300eb2d8211c/The_system_tries_to_find_translational_equivalents.jpg" /></p>
<h1 id="statistical-machine-translation"><a class="header" href="#statistical-machine-translation"><strong>Statistical machine translation</strong></a></h1>
<p>using word alignment</p>
<ol>
<li>Word-based translation</li>
<li>Phrase-based translation</li>
<li>Syntax-based translation</li>
<li>Hierarchical phrase-based translation</li>
</ol>
<p><strong>IBM Model 1</strong></p>
<p>all initial alignments have equal probability</p>
<p><strong>IBM Model 2</strong></p>
<p>take into account relative positions</p>
<p><strong>IBM Model 3</strong></p>
<p>take into account 1-n correspondences</p>
<p><strong>IBM Model 4</strong></p>
<p>consider moveable parts of a sentence</p>
<p><strong>IBM Model 5</strong></p>
<p>higher accuracy due to more complex calculations</p>
<h1 id="segment-based-machine-translation"><a class="header" href="#segment-based-machine-translation">Segment-based machine translation</a></h1>
<h1 id="neural-machine-translation"><a class="header" href="#neural-machine-translation">Neural machine t<strong>ranslation</strong></a></h1>
<p>Back translation</p>
<p>Translate from target language to source language</p>
<p>Sentence alignment:</p>
<p>two documents. Align the sentence so that we have sentence-level training examples</p>
<h2 id="models-1"><a class="header" href="#models-1"><strong>Models</strong></a></h2>
<ul>
<li>Translation language modelling: MLM pre-training has been extended to the multilingual setting by modifying MLM training to include concatenated translation pairs</li>
</ul>
<ol>
<li>Seq2seq with attention</li>
<li>Transformer</li>
<li>Conv Seq2Seq</li>
<li>Unsupervised MT</li>
<li>LASER, from facebook (multilingual sentence embedding)</li>
<li><a href="https://huggingface.co/transformers/model_doc/marian.html">MarianMT</a> (1000 models)</li>
<li><a href="https://github.com/facebookresearch/XLM">XLM</a></li>
</ol>
<h2 id="metrics"><a class="header" href="#metrics"><strong>Metrics</strong></a></h2>
<p>BLEU - Bilingual Evaluation Understudy Score: metric for evaluating a generated sentence to a reference sentence.</p>
<h1 id="datasets"><a class="header" href="#datasets"><strong>Datasets</strong></a></h1>
<p>WMT (Workshop on Statistical Machine Translation)</p>
<p>OPUS <a href="http://opus.nlpl.eu/">http://opus.nlpl.eu</a></p>
<p>CCMatrix</p>
<p>CCAligned</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pretraining-tasks"><a class="header" href="#pretraining-tasks">Pretraining tasks</a></h1>
<p><code>[MASK]</code> tokens are tokens to predict</p>
<div class="table-wrapper"><table><thead><tr><th>Pretraining task</th><th>Given input</th><th>Predict</th><th>Examples</th></tr></thead><tbody>
<tr><td>Language modeling (LM)</td><td>Token</td><td>Next token</td><td>GPT-XXX, Transformer XL</td></tr>
<tr><td>Masked language modeling (MLM)</td><td>Sentence with some <code>[MASK]</code> tokens</td><td><code>[MASK]</code> tokens</td><td>BERT</td></tr>
<tr><td>Permuted language modeling (PLM)</td><td></td><td></td><td>XLNet</td></tr>
<tr><td>Denoising autoencoder (DAE)</td><td>Sentence with some <code>[MASK]</code> tokens, random deletion, shuffling</td><td>Original input</td><td>BART, Pegasus, DAE</td></tr>
<tr><td>Next Sentence Prediction (NSP)</td><td>Inputs A and B</td><td>If A precedes B</td><td>BERT</td></tr>
<tr><td>Machine Translation (MT)</td><td></td><td></td><td>CoVe</td></tr>
</tbody></table>
</div>
<p><a href="https://arxiv.org/abs/2302.07730">Transformer models: an introduction and catalog</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="models-2"><a class="header" href="#models-2">Models</a></h1>
<p>&quot;Foundation language models&quot;</p>
<div class="table-wrapper"><table><thead><tr><th>Year</th><th>Model</th><th>Arch</th><th>Pretraining</th><th>Params</th><th>Applications</th></tr></thead><tbody>
<tr><td>2023</td><td>LLaMA</td><td>?</td><td>?</td><td>7B,13B,65B</td><td>?</td></tr>
<tr><td>2022</td><td>GPT-3.5</td><td>Decoder</td><td>LM</td><td>175B</td><td>Code generation, dialog</td></tr>
<tr><td></td><td>OPT</td><td>?</td><td></td><td></td><td></td></tr>
<tr><td></td><td>LAMDA</td><td>Decoder</td><td>LM</td><td>137B</td><td>General language modelling</td></tr>
<tr><td></td><td>ChatGPT</td><td>Decoder</td><td>LM</td><td>175B</td><td>Dialog</td></tr>
<tr><td></td><td>BLOOM</td><td>Decoder</td><td>LM</td><td>176B</td><td>Code generation</td></tr>
<tr><td></td><td>Minerva</td><td>Decoder</td><td>LM</td><td>540B</td><td>Mathematical reasoning</td></tr>
<tr><td></td><td>Chinchilla</td><td>Decoder</td><td>LM</td><td>70B</td><td>Dialog</td></tr>
<tr><td></td><td>PaLM</td><td>Decoder</td><td>LM</td><td>62B,540B</td><td>(general language tasks)</td></tr>
<tr><td>2021</td><td>HTML</td><td>Encoder/Decoder</td><td>DAE</td><td>400M</td><td>HTML prompting</td></tr>
<tr><td></td><td>Gopher</td><td>Decoder</td><td>LM</td><td>280B</td><td>General language modelling</td></tr>
<tr><td>2020</td><td>GPT-3</td><td>Decoder</td><td>LM</td><td>175B</td><td>Code generation, audio generation</td></tr>
<tr><td></td><td>Big Bird</td><td>Encoder</td><td>MLM</td><td>-</td><td>Longer sequence</td></tr>
<tr><td></td><td>ELECTRA</td><td>Encoder</td><td>RTD</td><td>110M-330M</td><td>Longer sequence</td></tr>
<tr><td></td><td>mBART</td><td>Encoder/Decoder</td><td>DAE</td><td>110M</td><td>Translation</td></tr>
<tr><td>2019</td><td>XLM-RoBERTa</td><td>Encoder</td><td>MLM</td><td>270M-550M</td><td>Translation, cross-lingual tasks</td></tr>
<tr><td></td><td>BART</td><td>Encoder/Decoder</td><td>DAE</td><td>110M</td><td>Text generation</td></tr>
<tr><td></td><td>ERNIE</td><td>Encoder</td><td>MLM</td><td>114M</td><td>Entity recognition</td></tr>
<tr><td></td><td>GPT-2</td><td>Decoder</td><td>LM</td><td>1.5B</td><td>Text generation, (general language tasks)</td></tr>
<tr><td></td><td>Transformer XL</td><td>Decoder</td><td>LM</td><td>151M</td><td>(general language tasks)</td></tr>
<tr><td></td><td>RoBERTA</td><td>Encoder</td><td>MLM</td><td>356M</td><td>Language understading, question answering</td></tr>
<tr><td></td><td>T5</td><td>Encoder/Decoder</td><td>DAE</td><td>11B</td><td>MT, question answering, abstractive summarisation</td></tr>
<tr><td></td><td>Pegasus</td><td>Encoder/Decoder</td><td>DAE,MLM</td><td>223M-568M</td><td>Summarisation</td></tr>
<tr><td></td><td>ALBERT</td><td>Encoder</td><td>MLM/NSP</td><td>12M-60M</td><td>Language understading, question answering</td></tr>
<tr><td></td><td>DistilBERT</td><td>Encoder</td><td>MLM/NSP</td><td>66M</td><td>Language understading, question answering</td></tr>
<tr><td></td><td>XLNet</td><td>Decoder</td><td>PLM</td><td>117-360M</td><td>(general language tasks)</td></tr>
<tr><td>2018</td><td>BERT</td><td>Encoder</td><td>MLM/NSP</td><td>110M</td><td>Language understading, question answering</td></tr>
<tr><td></td><td>GPT</td><td>Decoder</td><td>LM</td><td>117M</td><td>Text generation</td></tr>
<tr><td>2017</td><td>Transformer</td><td>Encoder+Decoder</td><td></td><td></td><td></td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="pretraining-tasks-1"><a class="header" href="#pretraining-tasks-1">Pretraining tasks</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="models-3"><a class="header" href="#models-3">Models</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Year</th><th>Model</th><th>Modes</th><th>Architecture</th><th>Params</th></tr></thead><tbody>
<tr><td></td><td>Flamingo</td><td></td><td></td><td></td></tr>
<tr><td></td><td>PaLI</td><td></td><td></td><td></td></tr>
<tr><td>2022</td><td>DALL•E 2</td><td>Image + text</td><td>Transformer</td><td></td></tr>
<tr><td>2022</td><td>Stable Diffusion</td><td>Image + text</td><td></td><td></td></tr>
<tr><td>2021</td><td>DALL•E</td><td>Image + language</td><td>Transformer</td><td></td></tr>
<tr><td></td><td>CLIP</td><td>Image + language</td><td>Transformer</td><td></td></tr>
<tr><td></td><td>Stable Diffusion</td><td>Image + language</td><td></td><td></td></tr>
<tr><td></td><td>DALL•E</td><td>Image + text</td><td>Transformer</td><td></td></tr>
<tr><td>?</td><td>GPT-3</td><td>Image + language</td><td>Transformer</td><td></td></tr>
<tr><td>?</td><td>GPT</td><td>Image + language</td><td>Transformer</td><td></td></tr>
<tr><td>2016</td><td>Show and Tell</td><td>Image + text</td><td></td><td></td></tr>
</tbody></table>
</div>
<ul>
<li><a href="https://openai.com/blog/clip/">CLIP</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="clustering-algorithms"><a class="header" href="#clustering-algorithms">Clustering algorithms</a></h1>
<p>“Meaningful collections / meaningful groups”</p>
<p>“How you choose helps you understand more about them”</p>
<p>Uses:</p>
<ul>
<li>Market segmentation</li>
<li>Medical. imaging</li>
<li>Anomaly detection</li>
<li>Image segmentation</li>
<li>Generalisation (less popular together with more popular videos)</li>
<li>User clustering</li>
</ul>
<p>Why transform data?</p>
<p>In clustering, you calculate the similarity between two examples by combining all the feature data for those examples into a numeric value. <strong>Combing feature data requires that the data have the same scale.</strong></p>
<h2 id="types-1"><a class="header" href="#types-1">Types</a></h2>
<ul>
<li>Centroid-based
<ul>
<li>k-means &amp; k-means++ (for choosing seeds)</li>
<li>FAISS (<a href="https://github.com/facebookresearch/faiss">facebookresearch / faiss</a>)</li>
</ul>
</li>
<li>Density-based
<ul>
<li>DBSCAN</li>
<li>OPTICS</li>
</ul>
</li>
<li>Distribution-based</li>
<li>Hierarchical</li>
<li>Unclassified
<ul>
<li>Mean shift</li>
</ul>
</li>
</ul>
<h2 id="metrics-1"><a class="header" href="#metrics-1">Metrics</a></h2>
<ul>
<li>Davies-Bouldin index</li>
<li>Silhouette score</li>
<li>Gini coefficient: measure degree of heterogeneity</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="self-supervised-learning"><a class="header" href="#self-supervised-learning">Self-supervised learning</a></h1>
<p>Training a model using labels that are inherent in the data, rather than requiring a separate set of labels.</p>
<p>The task that is used for pretraining is the <strong>pretext task</strong>. The tasks that we then use for fine-tuning are called <strong>downstream tasks</strong>. This is also <strong>transfer learning</strong>.</p>
<ul>
<li>Colorisation</li>
<li>Guessing image patches</li>
<li>Placing frames in thr right order</li>
<li>Inpainting</li>
<li>Classify corrupted images</li>
</ul>
<p>Choosing a pretext task</p>
<p>The tasks that you choose needs to be something that, if solved, would require an understanding of your data which would also be needed to solve your downstream task.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="semi-supervised-learning"><a class="header" href="#semi-supervised-learning">Semi-supervised learning</a></h1>
<h1 id="semi-supervised-learning-1"><a class="header" href="#semi-supervised-learning-1"><strong>Semi-supervised learning</strong></a></h1>
<p>Small amount of data and large amount of unlabelled data.</p>
<h1 id="weak-supervision"><a class="header" href="#weak-supervision"><strong>Weak supervision</strong></a></h1>
<p>Labelled data are noisy and imprecise.</p>
<p>Workflow</p>
<ol>
<li>Process unlabelled data to generate accuracies of label sources</li>
<li>Generate training labels</li>
<li>Train a powerful model</li>
</ol>
<h1 id="frameworks-1"><a class="header" href="#frameworks-1"><strong>Frameworks</strong></a></h1>
<p>Snorkel: aggregate noisy labelling function outputs to automatically label training data</p>
<p>FlyingSquid</p>
<p>FixMatch</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="intro-to-dl"><a class="header" href="#intro-to-dl">Intro to DL</a></h1>
<h1 id="terminologies-1"><a class="header" href="#terminologies-1"><strong>Terminologies</strong></a></h1>
<ul>
<li>architecture = model = network = algorithm</li>
<li>input = image = tensor = image matrix</li>
<li>output = convolved feature</li>
<li>input channels = input maps = depth</li>
<li>output channels = feature maps = activation map</li>
<li>filter = kernel = weights = feature extractor = convolution = feature detector</li>
<li>feature = structure (low-level, high-level)</li>
<li>resolution = dimension = size</li>
<li>depth = no. of channels/filters</li>
<li>class</li>
<li>example = observation = sample</li>
<li>Epoch = training step</li>
<li>Batch = iteration</li>
<li>Filter</li>
<li>Downsample = encode</li>
<li>Upsample = decode</li>
</ul>
<h1 id="why-deep-learning"><a class="header" href="#why-deep-learning"><strong>Why deep learning?</strong></a></h1>
<ul>
<li>Classical ML: Features are hand engineered. Hand engineered features are
<ol>
<li>Time-consuming</li>
<li>Brittle</li>
<li>Not scalable</li>
</ol>
</li>
<li>DL: Features are <strong>learned</strong>. Deep learning is able to extract salient information from raw data by developing a hierarchical representation of features. This automatic feature extraction is an intrinsic component of the architecture. For this reason, deep learning is often described as <strong>representation learning</strong>.</li>
</ul>
<p>Why now?</p>
<ol>
<li>Big data. Data is becoming more pervasive.</li>
<li>Hardware</li>
<li>Software</li>
</ol>
<h1 id="universal-approximation-theorem"><a class="header" href="#universal-approximation-theorem"><strong>Universal approximation theorem</strong></a></h1>
<p>A feedforward network with a single (hidden) layer is sufficient to approximate, to an arbitrary precision, any continuous function. (Neural networks are excellent function approximators.)</p>
<p><a href="https://twitter.com/gabrielpeyre/status/1304645917648269312">https://twitter.com/gabrielpeyre/status/1304645917648269312</a></p>
<h1 id="normalising-feature-values"><a class="header" href="#normalising-feature-values"><strong>Normalising feature values</strong></a></h1>
<ul>
<li>Roughly zero-centered, -1 to 1 often works well and roughly <strong>all our inputs are of the same scale</strong>.</li>
<li>Helps gradient descent converge. Avoid NaN</li>
<li>Avoiding outlier values can also help</li>
<li>Can use:
<ul>
<li>Linear scaling</li>
<li>Log scaling</li>
<li>Max min clipping</li>
</ul>
</li>
</ul>
<h1 id="networks"><a class="header" href="#networks"><strong>Networks</strong></a></h1>
<p>Perceptron (no hidden layer, with nonlinearity)</p>
<p>Deep neural network (multi-layer perceptron)</p>
<h1 id="perceptron-components"><a class="header" href="#perceptron-components"><strong>Perceptron components</strong></a></h1>
<ul>
<li>Inputs + Weights + bias. A high bias means that a neuron is more likely activated despite its weights.</li>
<li>Linear combination</li>
<li>Non-linearity (nonlinear activation functions)</li>
<li>Output</li>
</ul>
<p>Note that a combination of linear models is still linear ie b + wx + wx.</p>
<h1 id="activation-functions"><a class="header" href="#activation-functions"><strong>Activation functions</strong></a></h1>
<p>Decides if a neuron should be on or off, and if on, how useful is it. They also ensure that values are contained and don’t explode.</p>
<ul>
<li>Sigmoid</li>
<li>Softmax</li>
<li>ReLU (Rectified Linear Unit)</li>
<li>Leaky ReLU</li>
<li>CELU (Continuously Differentiable Exponential Linear Unit)</li>
<li>GELU (Gaussian Error Linear Unit)</li>
<li>Swish</li>
</ul>
<p>Importance of activation function and nonlinearity</p>
<p>The purpose of activation functions is to introduce non-linearities into the network. In real life, almost all of our data is non linear. Nonlinearities allow you to approximate arbitrarily complex functions by introducing nonlinearities into decision boundaries.</p>
<h1 id="loss-function"><a class="header" href="#loss-function"><strong>Loss function</strong></a></h1>
<p>cost function</p>
<p>objective function</p>
<p>empirical loss</p>
<p>empirical risk</p>
<p>Binary cross entropy / negative log loss</p>
<p>Formulated by Claude Shannon, this loss function compares how different two distributions (true and predicted) are.</p>
<h1 id="optimisation"><a class="header" href="#optimisation"><strong>Optimisation</strong></a></h1>
<p>Solving the weights of a network with loss function is a non-convex optimisation. Proper initialisation matters. If network is composed of differentiable functions, then we can probably learn from it using gradient descent.</p>
<h1 id="gradient-descent"><a class="header" href="#gradient-descent"><strong>Gradient descent</strong></a></h1>
<p><a href="https://www.youtube.com/watch?v=aircAruvnKk">https://www.youtube.com/watch?v=aircAruvnKk</a></p>
<p>Compute gradient using backpropagation = chain rule. How does a small change in one weight affect the final loss? Should a weight get nudged up or down? Which ones give most bang for buck (which one will have more effect on the cost function)?</p>
<p>We can compute the <strong>best direction</strong> that is mathematically guaranteed to be the direction of the steepest descend. This direction is related to the gradient of the loss function.</p>
<p>Backpropagation</p>
<p>Backpropagation can be thought of as gates communicating to each other, whether they want their outputs to increase or decrease, so as to make the final output value higher or lower.</p>
<p>Backpropagation will ensure that weights that need to be updated are updated <strong>proportionately</strong> to the loss function. Gradient signals are “distributed” to everyone.</p>
<p>Gradient on x*w</p>
<p>If x were extremely large (no preprocessing done), gradient of w will be very large too. As a result, one needs to compensate by lowering the learning rate by that factor. Another method is to perform <strong>batch normalisation</strong>. Gradients can also vanish because each additional layer can successfully reduce signals through activation functions like sigmoid. One way to prevent this is to use other activation functions like ReLU.</p>
<p>Learning rate</p>
<p>If you set your learning rate too small, you’re not really trusting your gradient on each step. What can happen is that you can get stuck in local minima, because you’re not being as aggressive as you should be to escape them. If you set your learning rate too large, you can overshoot completely and diverge. Setting the learning rate can be challenging in practice such that you avoid the local minima but small off such that you still converge.</p>
<p>How to set learning rate?</p>
<ul>
<li>Try different learning rates</li>
<li>Design a learning rate that ‘adapts’ to the landscape.</li>
<li>Learning rate schedulers</li>
<li>One-fit cycle</li>
<li>Depends on batch size (larger batch size means you are trusting the gradient more so learning rate can be increased)</li>
</ul>
<p>Learning rate schedulers</p>
<ul>
<li>Constant</li>
<li>Time-based decay</li>
<li>Step decay</li>
<li>Exponential decay</li>
<li>Lambda</li>
<li>Multistep LR</li>
<li>Cosine annealing LR</li>
<li>ReduceLR on plateau</li>
<li>Cyclic</li>
</ul>
<h1 id="gradient-descent-optimisation-algorithms"><a class="header" href="#gradient-descent-optimisation-algorithms"><strong>Gradient descent optimisation algorithms</strong></a></h1>
<ul>
<li>Vanilla</li>
<li>Momentum</li>
<li>NAG</li>
<li>RMSProp</li>
<li>Adam</li>
<li>RAdam</li>
<li>SWA</li>
</ul>
<h1 id="batch-gradient-descent-mini-batch-gradient-descent-stochastic-gradient-descent"><a class="header" href="#batch-gradient-descent-mini-batch-gradient-descent-stochastic-gradient-descent"><strong>(Batch) gradient descent, mini-batch gradient descent, stochastic gradient descent</strong></a></h1>
<p>Gradient in gradient descent is expensive to compute over all data points. Stochastic gradient descent computes over <strong>a single data point chosen randomly</strong>. The term &quot;stochastic&quot; comes from the fact that the gradient based on a single training sample is a &quot;stochastic approximation&quot; of the &quot;true&quot; cost gradient. The downside of using a single point is that it’s going to be too noisy. Middle ground is to take a mini-batch, where true gradient is approximated by taking the average of the gradients.</p>
<ul>
<li>More accurate estimation of gradient
<ul>
<li>Smoother convergence</li>
<li><strong>Allows for larger learning rates</strong> (because we trust the gradients more)</li>
</ul>
</li>
</ul>
<p>Stochastic gradient descent can be also taken to mean batch gradient descent.</p>
<h1 id="overfitting--regularisation"><a class="header" href="#overfitting--regularisation"><strong>Overfitting &amp; regularisation</strong></a></h1>
<ul>
<li>Dropout: randomly set some of the activation of the hidden neurons to 0 with some probability (usually 50%)</li>
<li>Early stopping</li>
<li>JUMP START</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-libraries"><a class="header" href="#tensor-libraries">Tensor libraries</a></h1>
<p>Frameworks</p>
<ul>
<li>NumPy</li>
<li>PyTorch &amp; TorchScript</li>
<li>TensorFlow</li>
<li>JAX = JIT + Autograd + XLA</li>
<li>Numba</li>
<li>Keras</li>
<li>PyTorch lightning</li>
</ul>
<hr />
<p><a href="https://github.com/ipython-books/cookbook-2nd/blob/master/chapter04_optimization/05_array_copies.md">ipython-books/cookbook-2nd</a></p>
<p>Why are NumPy arrays efficient?</p>
<ol>
<li>Data is stored stored contiguously (unlike Python)</li>
<li>Spatial locality (???)</li>
<li>Because of contiguity, vectorised instructions can be used (Intel's SSE and AVX).</li>
</ol>
<h1 id="view"><a class="header" href="#view">View</a></h1>
<pre><code class="language-python">X.view()

To check if an array is a view of another

y1.base is y

If none, it’s a copy
</code></pre>
<h1 id="creation"><a class="header" href="#creation"><strong>Creation</strong></a></h1>
<pre><code class="language-python">x = np.zeros((3,4,5))              # zeros
x = np.ones((3,4,5))               # ones
x = np.random.rand(3,4,5)          # uniform [0,1]
x = np.random.randint(0,21,15)
x = np.random.normal(size=(3,4,5)) # N(0,1)
x = np.random.rand(4)              # U(0,1)
x = np.array([0,0,0])              # from array
x = np.arange(0,15)
x = np.eye(3)                      # diagonal 3x3 matrix ones
</code></pre>
<pre><code class="language-python">x = torch.zeros((3,4,5))           # zeros
x = torch.ones((3,4,5))            # ones
x = torch.rand(3,4,5)              # uniform [0,1]
x = torch.randn(3,4,5)             # N(0,1)
x = torch.tensor([3.,4.,2.])       # from array
x = torch.empty(1,5,3)             # zeros
</code></pre>
<h1 id="mathematical-operations"><a class="header" href="#mathematical-operations"><strong>Mathematical operations</strong></a></h1>
<pre><code class="language-python">x.dot(x)           # matrix multiplication
x.argmin()         # index of min
</code></pre>
<pre><code class="language-python">torch.matmul(x, y)
torch.mm(x, y)
</code></pre>
<h1 id="info"><a class="header" href="#info"><strong>Info</strong></a></h1>
<pre><code class="language-python">x.shape
</code></pre>
<pre><code class="language-python">x.size()
</code></pre>
<h1 id="shape-manipulation"><a class="header" href="#shape-manipulation"><strong>Shape manipulation</strong></a></h1>
<pre><code class="language-python">x = x.reshape(1,-1)
x = x.reshape(1,5,2) 
np.reshape(x,(1,5,2))
x = x.view(1,5,-1)  reshape to (1,5,?) where ? Is inferred
np.squeeze([[[[1,2,3,4]]]])

TOrch:
xy.squeeze()
</code></pre>
<h1 id="permute"><a class="header" href="#permute"><strong>Permute</strong></a></h1>
<pre><code class="language-python">x.transpose(2, 0, 1)
</code></pre>
<pre><code class="language-python">x.permute
</code></pre>
<h1 id="expand-dimension"><a class="header" href="#expand-dimension"><strong>Expand dimension</strong></a></h1>
<pre><code class="language-python">x[:, np.newaxis]
np.expand_dims(axis=)

x.expand()
</code></pre>
<h1 id="sorting"><a class="header" href="#sorting"><strong>Sorting</strong></a></h1>
<pre><code class="language-python">x.sort(axis=)
np.argsort(a)
</code></pre>
<h1 id="concat"><a class="header" href="#concat"><strong>Concat</strong></a></h1>
<pre><code class="language-python">torch.cat()
</code></pre>
<h1 id="mask"><a class="header" href="#mask">Mask</a></h1>
<p>https://stackoverflow.com/questions/19984102/select-elements-of-numpy-array-via-boolean-mask-array/58365403#58365403</p>
<h1 id="gotchas"><a class="header" href="#gotchas">Gotchas</a></h1>
<ul>
<li>Gradiemts are accumulated. Must zero accordingly</li>
<li><code>with torch.nograd</code> ensures that in manual gradient update, a computation graph for differentiation isnt created</li>
<li>Optimiser.step() updates weights for you</li>
<li>Forward and callable</li>
<li>Requires_grad</li>
<li>When inheriting from nn.Module, the weights must be wrapped with torch.nn.Parameter() to be automatically registered as parameter. (Not sure if this is the right way but it’s something like that)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sparse-matrices"><a class="header" href="#sparse-matrices">Sparse matrices</a></h1>
<ul>
<li>
<p>CSR (compressed sparse column)</p>
<p>Write-once-read-many</p>
<p>matrix is represented using three 1D arrays for the non zero values</p>
<p>value = [5 8 3 6]</p>
<p>col = [0 1 2 1]</p>
<p>row = [0 0 2 3 4]</p>
<p>Fast row access and matrix-vector multiplications.</p>
</li>
<li>
<p>LIL (list of list)</p>
<p><code>[(row,col,val), (row,col,val), (row,col,val)]</code></p>
</li>
<li>
<p>DOK (dictionary of keys)</p>
<pre><code>{(row,col): val,
 (row,col): val}
</code></pre>
</li>
<li>
<p>COO (coordinate list)</p>
<p><code>(row,col,val), (row,col,val), (row,col,val)]</code></p>
</li>
<li>
<p>CSC (compressed sparse row)</p>
</li>
<li>
<p>Block sparse row</p>
</li>
</ul>
<p><strong>Code</strong></p>
<pre><code class="language-python">from scipy.sparse import csr_matrix, csc_matrix
from scipy.sparse import random

matrix = random(3,3, format='csr', density=0.4)

.todense()
.toarray()
.nnz
.data
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transfer-learning"><a class="header" href="#transfer-learning">Transfer learning</a></h1>
<h1 id="definitions--intuitions"><a class="header" href="#definitions--intuitions">Definitions / intuitions</a></h1>
<ul>
<li>&quot;Given a loss function, theoretically, the random model will have a higher loss (think loss landscape). This is what is meant by “knowing to do something”.&quot;</li>
<li>“Transfer learning is the idea that, if you know how to solve a task well, you should be able to transfer some of that understanding to solving related problems.”</li>
<li>“Transfer learning is a means to extract knowledge from a source setting and apply it to a different target setting.”
<ul>
<li>Train a model with a smaller dataset,</li>
<li>Improve generalisation, and</li>
<li>Speed up training.</li>
</ul>
</li>
<li>Transfer learning is a technique that takes a piece of a model that has already been trained on a related task and reusing it in a new model. The intuition behind this idea is, that also for other tasks or dataset the first layers of neural networks learn similar concepts to recognise basic structures such as blobs and edges. This concepts do not have be trained again from scratch when using pretrained models.</li>
<li><a href="http://cs231n.github.io/transfer-learning/">Transfer learning</a> is a technique in machine learning in which we apply knowledge from a source domain (e.g. ImageNet) to a target domain that may have significantly fewer data points. In practice, this generally involves initialising a model with pre-trained weights from ResNet, Inception, etc. and either using it as a feature extractor, or fine-tuning the last few layers on a new dataset. With transfer learning, these models can be re-purposed for any related task we want, from object detection for self-driving vehicles to generating captions for video clips. Use when:
<ul>
<li>Similar domain</li>
<li>Small dataset</li>
<li>Extract feature</li>
<li>Fine-tune last few layers</li>
</ul>
</li>
<li>The underlying idea of transfer learning is that neural net architectures will generalise for similar types of problems: for example, that many images have underlying features (such as corners, circles, dog faces, or wheels) that show up in a variety of different types of images. In contrast, the underlying idea of promoting neural architecture search for every problem is the opposite: that each dataset has a unique, highly specialised architecture it will perform best with.</li>
</ul>
<h1 id="how-can-knowledge-be-transferred"><a class="header" href="#how-can-knowledge-be-transferred">How can knowledge be transferred?</a></h1>
<ol>
<li>From a task to a downstream task (via sequential transfer learning or multitask learning)</li>
<li>From a domain to another domain (domain adaptation)</li>
<li>From a language to another language (cross-lingual learning)</li>
</ol>
<h1 id="who-can-use"><a class="header" href="#who-can-use">Who can use?</a></h1>
<ul>
<li>Small data</li>
<li>Pathetic computer</li>
</ul>
<h1 id="how-to-fine-tune"><a class="header" href="#how-to-fine-tune">How to fine-tune?</a></h1>
<p>Gradual unfreezing</p>
<p>Discriminative learning rates</p>
<p>One-cycle training</p>
<p>ImageNet pretraining has been quite successful</p>
<p>No. Of layers</p>
<p>Batch normalisation</p>
<p>ReLU</p>
<p>Dropouts</p>
<ul>
<li>architecture
<ul>
<li>Keep</li>
<li>Modify</li>
</ul>
</li>
<li>Weights
<ul>
<li>Don’t change (feature extraction)</li>
<li>Modify (fine-tuning the weights)</li>
</ul>
</li>
<li>Manner
<ul>
<li>One layer at a time (freezing)</li>
<li>Start with low learning rates</li>
<li>Regularisation (One way to minimise catastrophic forgetting is to encourage target model parameters to stay close to the parameters of the pretrained model using a regularisation term)</li>
</ul>
</li>
</ul>
<p>Given a loss function, theoretically, the random model will have a higher loss (think loss landscape). This is what is meant by “knowing to do something”.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="weight-initialisation"><a class="header" href="#weight-initialisation">Weight initialisation</a></h1>
<p><a href="https://www.deeplearning.ai/ai-notes/initialization/">https://www.deeplearning.ai/ai-notes/initialization/</a></p>
<p>On weight initialisation in deep neural networks</p>
<h1 id="motivation-1"><a class="header" href="#motivation-1"><strong>Motivation</strong></a></h1>
<p>Backpropagated gradients are either amplified or minimised. As a results, training is slowed down or diverges.</p>
<h1 id="goal"><a class="header" href="#goal"><strong>Goal</strong></a></h1>
<p>Gradient signal should not be multiplied by values that are too small or too large in any layer.</p>
<h1 id="proposition"><a class="header" href="#proposition"><strong>Proposition</strong></a></h1>
<p>It is proposed that across layers:</p>
<ol>
<li>Mean of activations should be 0 (so that it’s easier to determine what is the right variance to use for different nonlinear activation functions)</li>
<li>Variance of nonlinear activations is the same (intuitively, it maintains magnitude of the signals)</li>
</ol>
<p>such that the resulting backpropagated gradient signal will not be multiplied by values too small or too large in any layer.</p>
<p>$$
E[a^{[l-1]}] = E[a^{[l]}] \
Var(a^{[l-1]}) = Var(a^{[l-1]})
$$</p>
<h1 id="assumptions"><a class="header" href="#assumptions"><strong>Assumptions</strong></a></h1>
<ul>
<li>Weights are IID.</li>
<li>Inputs to the first layer are IID with mean 0 and variance 1.</li>
<li>Weights and inputs are mutually independent.</li>
</ul>
<h1 id="types-of-initialisation"><a class="header" href="#types-of-initialisation"><strong>Types of initialisation</strong></a></h1>
<ul>
<li>Initialise with the same number = symmetrical
<ul>
<li>Cases
<ul>
<li>All zeros =&gt; network will not learn</li>
<li>All ones =&gt; does not break symmetry</li>
<li>All small =&gt; vanishing gradients; network will not learn</li>
<li>All big =&gt; exploding gradients</li>
</ul>
</li>
</ul>
</li>
<li>Initialise with different numbers i.e. random
<ul>
<li>Cases
<ul>
<li>Too large =&gt; exploding gradients</li>
<li>Too small =&gt; vanishing gradients</li>
<li>Just nice. We want the activations to have same mean and variance across, to prevent exploding or vanishing gradients</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="initialisations-to-use-for-nonlinear-activation-functions"><a class="header" href="#initialisations-to-use-for-nonlinear-activation-functions"><strong>Initialisations to use for nonlinear activation functions</strong></a></h1>
<ul>
<li>
<p>tanh: Xavier</p>
<p>$$
N(0,\frac{1}{n^{(l-1)}})
$$</p>
</li>
<li>
<p>sigmoid: Kumar</p>
<p>$$
N(0,\frac{3.6^2}{n^{(l-1)}})
$$</p>
</li>
<li>
<p>ReLU: He</p>
<p>$$
N(0,\frac{2}{n^{(l-1)}})
$$</p>
</li>
</ul>
<h1 id="initialisation"><a class="header" href="#initialisation">Initialisation</a></h1>
<h2 id="xavier-initialisation"><a class="header" href="#xavier-initialisation">Xavier initialisation</a></h2>
<p>$$
N(0,\frac{1}{n^{(l-1)}})
$$</p>
<h2 id="he-initialisation"><a class="header" href="#he-initialisation">He initialisation</a></h2>
<p>$$
N(0,\frac{2}{n^{(l-1)}})
$$</p>
<h2 id="others"><a class="header" href="#others">Others</a></h2>
<ul>
<li>Xavier uniform</li>
<li>He uniform</li>
<li>Standard normal</li>
<li>Uniform</li>
<li>Zeros / other constants
<ul>
<li>Initialising all the weights with zeros leads the neurons to learn the same features during training.</li>
<li>Thus, both hidden units will have identical influence on the cost, which will lead to identical gradients. Thus, both neurons will evolve symmetrically throughout training, effectively preventing different neurons from learning different things.</li>
</ul>
</li>
</ul>
<h1 id="terms"><a class="header" href="#terms"><strong>Terms</strong></a></h1>
<p>Kaiming = Kaiming He</p>
<p>Glorot = Xavier Glorot</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bonus-questions"><a class="header" href="#bonus-questions">Bonus questions</a></h1>
<p>Lack of data?</p>
<ul>
<li>Open source data</li>
<li>Augmentation</li>
<li>Synthetic data</li>
<li>Transfer learning</li>
</ul>
<p><strong>Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI</strong></p>
<p><a href="https://arxiv.org/abs/2201.00650">https://arxiv.org/abs/2201.00650</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="frameworks-2"><a class="header" href="#frameworks-2">Frameworks</a></h1>
<p>TensorFlow, Keras</p>
<p>PyTorch, PyTorch Lightning, einops</p>
<p>flashlight</p>
<p>JAX, Trax</p>
<p>Create ML</p>
<p>PlaidML</p>
<p>Core ML</p>
<p>turicreate</p>
<p>TensorFlowJS</p>
<p>Darknet</p>
<p><a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a></p>
<p>ONNX</p>
<p>Accelerate</p>
<p>Intel MKL</p>
<p>MKL-DNN</p>
<p>BLAS</p>
<p>LAPACK</p>
<p>CUDA</p>
<p>Metal</p>
<p>PyOpenCL</p>
<h1 id="data-manipulation"><a class="header" href="#data-manipulation">Data manipulation</a></h1>
<p>cuDF</p>
<p>NumPy</p>
<p>pandas</p>
<p>ArrayFire</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="improving-predictive-power"><a class="header" href="#improving-predictive-power">Improving predictive power</a></h1>
<ul>
<li>
<p>Progressive resizing</p>
</li>
<li>
<p>Mixup augmentation</p>
</li>
<li>
<p>Removing wrongly classified test images</p>
</li>
<li>
<p>Ensembling</p>
</li>
<li>
<p>Model Fine-tuning using discriminative learning rate etc</p>
</li>
<li>
<p>Model distillation: large models or ensembles of models may be distilled into a single, smaller model</p>
</li>
</ul>
<p>Progressive Labelling</p>
<p>MixMatch</p>
<p>Catastrophic Forgetting is what limits learning rates at small batch sizes.</p>
<p>Cutout regularisation. Zero out a random 8x8 square subset of an image.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sgd-optimisers"><a class="header" href="#sgd-optimisers">SGD optimisers</a></h1>
<p><a href="https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9">10 Stochastic Gradient Descent Optimisation Algorithms</a></p>
<ul>
<li>AdamW</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="limitations-and-new-frontiers"><a class="header" href="#limitations-and-new-frontiers">Limitations and new frontiers</a></h1>
<p><img src="./Popularity.png" alt="Limitations%20and%20new%20frontiers%2082b68cc6c3af48c7bcee686b2f8c2e5c/Popularity.png" /></p>
<h3 id="neural-networks-only-accept-certain-input-types"><a class="header" href="#neural-networks-only-accept-certain-input-types"><strong>Neural networks only accept certain input types</strong></a></h3>
<p>Effect:</p>
<ul>
<li>Difficult to encode structure and prior knowledge</li>
</ul>
<p>Frontiers:</p>
<ul>
<li>2D spatial structure like images - CNN.</li>
<li>Graph data like social networks, internet traffic, state machines, mobility &amp; transport, molecules, biological networks - graph convolutional networks.</li>
<li>3D data (point clouds: unordered sets with spatial dependence between points) - CNN.</li>
</ul>
<h3 id="neural-networks-are-excellent-function-approximators"><a class="header" href="#neural-networks-are-excellent-function-approximators"><strong>Neural networks are excellent function approximators</strong></a></h3>
<p>Effect:</p>
<ul>
<li>Poor generalisation, memorises data. Does not work on unseen data.</li>
<li>Easily fooled by adversarial attacks (image + perturbation = ???).</li>
</ul>
<p>Frontiers:</p>
<ul>
<li>(See below on uncertainty)</li>
</ul>
<h3 id="neural-network-predictions-are-point-predictions"><a class="header" href="#neural-network-predictions-are-point-predictions"><strong>Neural network predictions are point predictions</strong></a></h3>
<p>Effect:</p>
<ul>
<li>Cannot quantify uncertainty for unseen data.</li>
</ul>
<p>Frontiers:</p>
<ul>
<li>Bayesian deep learning for uncertainty. Rather then learning the weights directly, we learn a posterior over the weights i.e. P(W|X,Y). This posterior is intractable, however.</li>
<li>Ensembling for uncertainty estimation.</li>
<li>Evidential deep learning: directly learn the underlying uncertainty using evidential distributions.</li>
<li>Multi-task learning using uncertainty</li>
</ul>
<h3 id="neural-networks-are-large"><a class="header" href="#neural-networks-are-large"><strong>Neural networks are large</strong></a></h3>
<p>Effect:</p>
<ul>
<li>Data hungry</li>
<li>Computationally intensive</li>
</ul>
<h3 id="neural-networks-are-complex"><a class="header" href="#neural-networks-are-complex"><strong>Neural networks are complex</strong></a></h3>
<p>Effect:</p>
<ul>
<li>Requires expert knowledge to design and fine tune</li>
<li>Finicky to optimise: non-convex, choice of architecture, learning parameters</li>
<li>Uninterpretable</li>
</ul>
<p>Frontiers:</p>
<ul>
<li>Automated machine learning for NAS.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learning-rate-scheduler"><a class="header" href="#learning-rate-scheduler">Learning rate scheduler</a></h1>
<ul>
<li>Cosine</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="backpropagation-softmax-and-categorical-cross-entropy"><a class="header" href="#backpropagation-softmax-and-categorical-cross-entropy">Backpropagation softmax and categorical cross entropy</a></h1>
<pre><code class="language-python">import torch.nn.functional as F
import torch.nn as nn

y = torch.tensor([[0,0,1]], dtype=torch.float32)

x = torch.tensor([[2,3]], dtype=torch.float32)

y_true = torch.tensor([2], dtype=torch.long)

linear = nn.Linear(2,3,bias=False)

linear.weight.data = torch.tensor([[-1,1],[2,-1],[0,2]], dtype=torch.float32)

z = linear(x)

y_pred = F.softmax(z, dim=1)

#loss = F.nll_loss(y_pred, y_true)
loss = -torch.log(y_pred[y==1])

z.retain_grad()
loss.retain_grad()
y_pred.retain_grad()
loss.backward()
</code></pre>
<p><img src="backpropagation-softmax-and-categorical-cross.png" alt="Backpropagation%20softmax%20and%20categorical%20cross%20entr%20cec73119cc9b460e97708a3e433032d2/Untitled.png" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hyperparameter-search"><a class="header" href="#hyperparameter-search">Hyperparameter search</a></h1>
<ul>
<li>Grid search</li>
<li>One learning rate cycle / one-fit cycle</li>
</ul>
<p>(search for the right learning rate) start low lr, increase exponentially for every batch. Plot LOSS vs. LR. We need to select a point on the graph <strong>with the fastest decrease in the loss</strong>. In this example, the loss function decreases fast when the learning rate is between 0.001 and 0.01.</p>
<p><img src="hyperparameter-search.png" alt="Hyperparameter%20search%20729c5649a5ed47d1b28eaad2e1090ebc/Untitled.png" /></p>
<p>Subsequently, use a cyclic learning rate scheduler and use this learning rate as the max.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="layers"><a class="header" href="#layers">Layers</a></h1>
<hr />
<h1 id="dropout"><a class="header" href="#dropout"><strong>Dropout</strong></a></h1>
<p>allows training on smaller datasets without over-fitting.</p>
<h1 id="batch-normalization"><a class="header" href="#batch-normalization"><strong>Batch normalization</strong></a></h1>
<p>allows for faster training. Normalise each pixel value across mini-batch</p>
<p>Make sure to scale the data if it’s on a very different scales. If we don’t scale the data, the level curves (contours) would be narrower and taller which means it would take longer time to converge (see figure 3).</p>
<p><img src="layers-Normalized.png" alt="Layers%206baf4091115f46f885e9a4718180f43f/Normalized.png" /></p>
<h1 id="skip-connections"><a class="header" href="#skip-connections"><strong>Skip connections</strong></a></h1>
<p>why do very deep nets perform worse as you keep adding layers?</p>
<p>Addressing the problem of training a really deep architecture by introducing skip connections: layers can copy their inputs to the next layer</p>
<p>Skip connections, which are employed in ResNet and DenseNet allow to build deeper architectures, while mitigating the vanishing gradient problem. All we have to do is to add the output of previous layers to the input of layers located deeper in our network, <strong>before</strong> the activation function is applied:</p>
<p>Skip connections work, because by connecting layers via shortcuts, we can at least learn the identity function. The intuition behind this technique is, that gradients do not have to be backpropagated solely through convolutional (or fully connected) layers, which cause gradients to diminish once they reach the earlier layers of the network. They can rather “skip” layers through the addition operation of the skip connection.</p>
<p><img src="layers-18Vhd39FU4B-ZDmRQ2m-fPA.png" alt="Layers%206baf4091115f46f885e9a4718180f43f/18Vhd39FU4B-ZDmRQ2m-fPA.png" /></p>
<p>Residual learning: instead of trying to learn some features, we try to learn some residual. Residual can be simply understood as subtraction of feature learned from input of that layer</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="improving-speed--accuracy"><a class="header" href="#improving-speed--accuracy">Improving speed / accuracy</a></h1>
<p><a href="https://myrtle.ai/how-to-train-your-resnet/">https://myrtle.ai/how-to-train-your-resnet/</a></p>
<h1 id="during-training"><a class="header" href="#during-training"><strong>During training</strong></a></h1>
<ul>
<li>Data
<ul>
<li>Perform preprocessing once before training</li>
<li>Curriculum learning - train on simple examples, then the hard ones</li>
</ul>
</li>
<li>Architecture
<ul>
<li>Mixed precision training</li>
<li>Smaller model</li>
<li>Engineering layers</li>
<li>Transfer learning</li>
</ul>
</li>
<li>Hyperparameters
<ul>
<li>High learning rates (super convergence)</li>
<li>Increase batch size</li>
</ul>
</li>
<li>Optimiser / regularisation / loss
<ul>
<li>Mixup regularisation</li>
<li>AdamW</li>
<li>Label smoothing</li>
</ul>
</li>
</ul>
<h1 id="during-inference"><a class="header" href="#during-inference"><strong>During inference</strong></a></h1>
<ul>
<li>Quantisation. Stores weights in low precision formats
<ul>
<li>fixed point vs floating point</li>
<li>post-training quantisation vs quantisation-aware training</li>
</ul>
</li>
<li>Pruning
<ul>
<li>Set some weights to 0. This cuts connections.</li>
</ul>
</li>
<li>Low Rank Approximation.
<ul>
<li>convolution layer can be broken down into two layers</li>
</ul>
</li>
<li>Weight sharing
<ul>
<li>Use means clustering to cluster 2.09, 2.12, 1.92, 1.87 and make them be 2. Stick to 2 bits for FCN and 4 bits for CNN</li>
</ul>
</li>
<li>Pruning &amp; training iteratively
<ul>
<li>Prune then retrain using a super small learning rate (1e-5)</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="activation-functions-1"><a class="header" href="#activation-functions-1">Activation functions</a></h1>
<p>Non-linearity functions</p>
<ul>
<li>ReLU</li>
<li>GeLU</li>
<li>SwiGLU</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deep-generative-models"><a class="header" href="#deep-generative-models">Deep generative models</a></h1>
<hr />
<p>Supervised learning: learn function to map x to y.</p>
<p>Unsupervised learning: learn hidden or underlying structure of data</p>
<p>Generative modelling: learn a model that represents distribution of data</p>
<p>Main tasks:</p>
<ul>
<li>Density estimation</li>
<li>Sample generation</li>
</ul>
<h1 id="why-learn-generative-models"><a class="header" href="#why-learn-generative-models">Why learn generative models?</a></h1>
<p>Debiasing</p>
<p>Outlier detection</p>
<h1 id="generative-models"><a class="header" href="#generative-models">Generative models</a></h1>
<p><img src="Deep_Generative_Modeling_Summary.png" alt="Deep_Generative_Modeling_Summary.png" /></p>
<ul>
<li>Autoencoder</li>
<li>VAE</li>
<li>GAN</li>
</ul>
<aside>
💡 **Autoencoders**
Bottleneck hidden layer foreces network to learn a compressed latent representation. Reconstruction loss forces the latent representation to capture as much information about the data as possible.
</aside>
<h2 id="autoencoder"><a class="header" href="#autoencoder">Autoencoder</a></h2>
<p><img src="Autoencoders_background.png" alt="Autoencoders_background.png" /></p>
<p>Encoder learns mapping from the data x to a low-dimensional latent space z (“compressed”).</p>
<p>Decoder learns mapping from latent z to a reconstructed observation, x_hat.</p>
<p>Loss function is L(x, x_hat). It doesn’t use any labels.</p>
<p>Reconstruction loss forces the latent representation to capture as much information about the data as possible.</p>
<h2 id="vae"><a class="header" href="#vae">VAE</a></h2>
<p><img src="VAE_optimization.png" alt="VAE_optimization.png" /></p>
<p>Variational autoencoder</p>
<p>Instead of learning a deterministic latent vector z, we learn a vector of mean and a vector std that parametrise the probability distribution for each of the latent variables</p>
<p><img src="VAE_optimization%201.png" alt="VAE_optimization%201.png" /></p>
<p><img src="VAE_optimization%202.png" alt="VAE_optimization%202.png" /></p>
<p><img src="Reparametrizing_the_sampling_layer.png" alt="Reparametrizing_the_sampling_layer.png" /></p>
<p><img src="VAEs_Latent_perturbation.png" alt="VAEs_Latent_perturbation.png" /></p>
<p><img src="VAEs_Latent_perturbation%201.png" alt="VAEs_Latent_perturbation%201.png" /></p>
<h2 id="gan"><a class="header" href="#gan">GAN</a></h2>
<p>Generative Adversarial Network</p>
<p>Instead of explicitly modelling the density (distribution of data), we just sample to generate new instances. However, we can’t sample from complex distribution directly. Thus the solution is to sample from something simple (noise), <strong>learn a transformation</strong> to the training distribution.</p>
<aside>
💡 We also cannot measure the difference of the generated samples with training samples because it's too expensive.
</aside>
<p>Adversaries (neural networks): </p>
<ul>
<li>The generator turns noise into an imitation of the data</li>
<li>The discriminator tries to discern between a fake generated by the generator and the true data.</li>
</ul>
<h1 id="uses"><a class="header" href="#uses">Uses</a></h1>
<p>Style transfer: CycleGAN</p>
<h1 id="mitigating-bias-through-learned-latent-structure"><a class="header" href="#mitigating-bias-through-learned-latent-structure">Mitigating bias through learned latent structure</a></h1>
<ol>
<li>Learn latent structure using VAE.</li>
<li>Estimate distribution. (How?)</li>
<li>Adaptively resample data.</li>
<li>Learn from fair data distribution.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="decision-tree"><a class="header" href="#decision-tree">Decision tree</a></h1>
<p><strong>#nonparametric</strong> <strong>#nonprobabilistic</strong></p>
<p>Keep splitting, split based on highest Gini Gain or Information Gain.</p>
<blockquote>
<p>💡 Gini impurity is a way of measuring if a split is &quot;good&quot;. Calculate Gini impurities (1) before split, (2) left branch and (3) right branch. Then weight the impurities of each branch (2) and (3). Then calculate how much impurity is removed by taking (1) minus the weighted (2) and (3).</p>
</blockquote>
<p>Try every split:</p>
<ul>
<li>Every feature</li>
<li>Every possible threshold (optimisable)</li>
</ul>
<p>Stop when:</p>
<ul>
<li>All Gini gains are the same</li>
<li>No Gini gain</li>
</ul>
<p>Algorithms:</p>
<ul>
<li>ID3 (multiway)
<ul>
<li>Brute force</li>
</ul>
</li>
<li>C4.5 (binary)
<ul>
<li>Brute force</li>
</ul>
</li>
<li>CART
<ul>
<li>Construct binary trees from using features and thresholds that yield highest information gain</li>
</ul>
</li>
</ul>
<blockquote>
<p>👉 Tree-based algorithms don’t require scaling!</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dbscan"><a class="header" href="#dbscan">DBSCAN</a></h1>
<p>Density-based spatial clustering of applications with noise</p>
<p><strong>#nonparametric</strong> <strong>#nonprobabilistic</strong></p>
<p>The DBSCAN algorithm views clusters as areas of high density separated by areas of low density.</p>
<ol>
<li>Choose 2 numbers: max_distance, min_points</li>
<li>Pick a random datapoint. This is cluster A</li>
<li>Criteria for datapoints to be in this cluster:
<ol>
<li>They are within a distance of max_distance</li>
<li>There are more than min_points datapoints</li>
</ol>
</li>
<li>Once run out of points, find another datapoint that has no cluster. This is Cluster B.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="evolutionary-algorithms"><a class="header" href="#evolutionary-algorithms">Evolutionary algorithms</a></h1>
<p>Subject a <strong>population</strong> to a heuristic survival-of-the-fittest competition. Individuals that score higher on the <strong>fitness function</strong> are granted more <strong>offspring</strong> in the next generation through <strong>crossover</strong> and <strong>mutation</strong> (slightly perturbed copes of themselves or combinations of themselves with other individuals). Individuals that score poorly are removed from the population.</p>
<ul>
<li>Genetic algorithm</li>
<li>Evolution strategy</li>
<li>Natural evolution strategy</li>
</ul>
<h1 id="natural-evolution-strategies-openai"><a class="header" href="#natural-evolution-strategies-openai">Natural Evolution Strategies (OpenAI)</a></h1>
<p>Individuals come from a probability distribution (usually Gaussian) around a single set of parameters. Iteratively update this population distribution such that average fitness of individuals drawn from population is maximised. Objective function is differentiable.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gaussian-process"><a class="header" href="#gaussian-process">Gaussian process</a></h1>
<pre><code class="language-python">import numpy as np
from sklearn.metrics.pairwise import rbf_kernel

class Kernel:
    @staticmethod
    def rbf(x_1, x_2):
        K = rbf_kernel(x_1, x_2)
        return K

class GaussianProcess:

    def __init__(self, X, y, kernel=&quot;rbf&quot;):
        self.X = X
        self.y = y

        # Prepare kernel
        self.k = Kernel.rbf(self.X, self.X)

        # Invert kernel
        self.k_inv = np.linalg.inv(self.k)

    def hey(self):
        pass

    def update(self, X_new, y_new):
        &quot;&quot;&quot;Not used&quot;&quot;&quot;

        self.X = np.concatenate(self.X, X_new, axis=0)
        self.y = np.concatenate(self.y, y_new, axis=0)

        # Update the covariance matrix for existing training points
        self.k = Kernel.rbf(self.X, self.X)
        self.k_inv = np.linalg.inv(self.k)

    def predict(self, X_new):
        &quot;&quot;&quot;Predict a value&quot;&quot;&quot;

        # Get all the kernel parts
        k_new = np.array(
            [Kernel.rbf(X_new, np.array([x])).reshape(-1) for x in self.X])
        k_newnew = Kernel.rbf(X_new, X_new)

        # Mean
        y_pred = np.dot(k_new.T, self.k_inv).dot(self.y)
        y_pred = y_pred.squeeze()

        # Covariance
        sigma = k_newnew - np.dot(k_new.T, self.k_inv).dot(k_new)
        sigma = sigma.squeeze()

        return y_pred, sigma
</code></pre>
<pre><code class="language-python">import numpy as np
from gp import Kernel, GaussianProcess
import matplotlib.pyplot as plt

# Real
X = np.linspace(1,20,10000)
X = X.reshape(1,-1)
y = np.sin(X)
plt.scatter(X,y, color='black')

# Data
SIZE = 5
X = np.random.uniform(low=1, high=20, size=SIZE)
X = X.reshape(-1,1)
y = np.sin(X) + np.random.normal(0, 0.3, SIZE).reshape(-1,1)
plt.scatter(X,y, color='yellow')

# New data
X_new = np.random.uniform(low=1, high=20, size=100)
X_new = X_new.reshape(-1,1)

# GP
gp = GaussianProcess(X, y)
y_new = gp.predict(X_new)
plt.scatter(X_new,y_new, color='red', alpha=0.5)

# Plot
plt.show()
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gmm"><a class="header" href="#gmm">GMM</a></h1>
<p>Gaussian Mixture Model</p>
<p><strong>#parametric</strong> <strong>#probabilistic</strong></p>
<p>A probabilistic model that assumes all the data points are generated from a mixture of Gaussian distributions with unknown parameters</p>
<p>Optimiser: EM algorithm</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hierachical-clustering"><a class="header" href="#hierachical-clustering">Hierachical clustering</a></h1>
<ul>
<li>agglomerative (slowly accumulate)</li>
<li>divisive (slowly split)</li>
</ul>
<p>This is achieved by use of a metric and a linkage criterion.</p>
<p>Examples of linkage criteria:</p>
<ul>
<li>Single linkage (minimum)</li>
<li>Complete linkage (maximum)</li>
<li>Average linkage (average between pairs)</li>
<li>Ward</li>
<li>Centroid</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gradient-boosting"><a class="header" href="#gradient-boosting">Gradient boosting</a></h1>
<p><img src="./gradient-boosting.png" alt="Gradient boosting" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="k-nn"><a class="header" href="#k-nn">k-NN</a></h1>
<p><strong>#nonparametric</strong> <strong>#nonprobabilistic</strong></p>
<p>Use a distance metric to calculate the \( k \) closest neighbours. Then, take its mean (or median etc.).</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png" alt="k-NN" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="k-means"><a class="header" href="#k-means">k-means</a></h1>
<p><strong>#nonparametric</strong></p>
<p>Assign k centroids randomly</p>
<p>Get each data point to see which centroid it’s closest to, and assign a class</p>
<p>Calculate centre of points for each group</p>
<p>Reassign the k centroids</p>
<p>Use silhouette heuristic or the elbow method to determine a reasonable value for k</p>
<p><img src="./k-means.png" alt="k-means" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linear-models"><a class="header" href="#linear-models">Linear models</a></h1>
<p>Uses OLS. See page for assumptions. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logistic-regression"><a class="header" href="#logistic-regression">Logistic regression</a></h1>
<p><strong>#parametric</strong> <strong>#probabilistic</strong></p>
<p>A model that predicts the probability using the logistic function $$\frac{1}{1+\exp(-x)}$$</p>
<p>Model:</p>
<p>$$
\hat{p}=\frac{1}{1+\exp(-\sum_i w_i x_i)} \in[0,1]
$$</p>
<p>A regression model whose output (termed as logits) is mapped from a real number to $(0,1)$ through the use of logistic function, which is the inverse of log odds. Log of odds is a measure of odds, which is a ratio (of probabilities).</p>
<p>To get the loss function, notice that each sample can be considered as a Bernoulli trial hence the model follows a Bernoulli distribution. Our objective is to maximise the likelihood, which is equivalent to minimising the negative of maximum likelihood.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mean-shift"><a class="header" href="#mean-shift">Mean shift</a></h1>
<p><strong>#nonparametric</strong></p>
<p>Popular in computer vision</p>
<p>Builds on KDE</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="naive-bayes"><a class="header" href="#naive-bayes">Naive Bayes</a></h1>
<p><strong>#probabilistic</strong></p>
<p>Assumes strong independence assumption between features, where each feature x is a particular distribution (usually Gaussian), so need to get the mean and std dev.</p>
<p><a href="https://remykarem.github.io/blog/naive-bayes.html">https://remykarem.github.io/blog/naive-bayes.html</a></p>
<p>Inference time:</p>
<p>$$
\mathbf{P}(\text{class} | x) = \frac{\mathbf{P}(\text{class}) × \mathbf{P}(x | \text{class})}{\mathbf{P}(\text{data})}
$$</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pca"><a class="header" href="#pca">PCA</a></h1>
<p>Principal Component Analysis</p>
<p><strong>#parametric</strong> <strong>#nonprobabilistic</strong></p>
<p><a href="https://towardsdatascience.com/visualizing-principal-component-analysis-with-matrix-transforms-d17dabc8230e?gi=2dbc0f4e5157">https://towardsdatascience.com/visualizing-principal-component-analysis-with-matrix-transforms-d17dabc8230e?gi=2dbc0f4e5157</a></p>
<p>Premise: the useful information is the underlying axes of data that gives you most variance</p>
<ul>
<li>Linear dimension reduction technique</li>
<li>Things that are different end up very far apart</li>
<li>Maximises variance and preserves large pairwise distances</li>
<li>Computationally cheap</li>
<li>“Redefine new axes”</li>
</ul>
<p><strong>Principal components</strong></p>
<p>They are the</p>
<ul>
<li>Underlying “axes” of data</li>
<li>= “directions” (= eigenvectors) where the data is most spread out, i.e have the most variance (variance = eigenvalues)
<ul>
<li>No. of eigenvalues/eigenvectors equals to no. of dimensions of data</li>
<li>The eigenvectors are perpendicular (= orthogonal) to each other</li>
</ul>
</li>
</ul>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Generate data
angle = np.radians(30.)
x1 = np.random.normal(scale=8, size=100)
x2 = x1*np.tan(angle) + np.random.normal(scale=3, size=100)
# x2 = np.random.normal(scale=3, size=100)
x1 = x1-np.mean(x1)
x2 = x2-np.mean(x2)
data = np.array([x1, x2])

# PCA
pca = PCA()
pca.fit(data.T)

# Matrix transformation
# angle = np.radians(30. - 360.) # same
angle_derotate = -angle
derotate = np.array([[np.cos(angle_derotate), -np.sin(angle_derotate)],
                     [np.sin(angle_derotate), np.cos(angle_derotate)]])
derotated_data = np.matmul(derotate, data)

rotate = np.array([[np.cos(angle_derotate), np.sin(angle_derotate)],
                     [-np.sin(angle_derotate), np.cos(angle_derotate)]])
rotated_data = np.matmul(data.T, rotate)

# Get explained variances
print(&quot;Variance in X: {:0.1f}&quot;.format(np.var(derotated_data[0])))
print(&quot;Variance in Y: {:0.1f}&quot;.format(np.var(derotated_data[1])))
print(pca.explained_variance_)

# Get the principal components
print(derotate)
print(rotate)
print(pca.components_.T)

# Covariance
# print(np.cov(data))
# print(np.matmul(np.matmul(derotate, data).T, rotate)) ????
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="svm"><a class="header" href="#svm">SVM</a></h1>
<p>Support Vector Machine</p>
<p>Find a separate hyperplane (&quot;decision boundary&quot;) that has the highest margin. The datapoints which are at the margin are called support vectors.</p>
<p>“Large-margin classifier”</p>
<ul>
<li>Linear separable</li>
<li>Nonlinear separable
<ul>
<li><strong>Soft Margin</strong>
Two types of misclassifications are tolerated by SVM under soft margin:
<ul>
<li>The dot is on the wrong side of the decision boundary but on the correct side/ on the margin (shown in left)</li>
<li>The dot is on the wrong side of the decision boundary and on the wrong side of the margin (shown in right)</li>
</ul>
</li>
<li><strong>Kernel Tricks</strong>
<ul>
<li>What Kernel Trick does is it utilises existing features, applies some transformations, and creates new features.</li>
<li>Think of the polynomial kernel as a transformer/processor to generate new features by applying the polynomial combination of all the existing features.</li>
<li>Think of the Radial Basis Function kernel as a transformer/processor to generate new features by measuring the distance between all other dots to a specific dot/dots — centres.</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="t-sne"><a class="header" href="#t-sne">t-SNE</a></h1>
<p><strong>#nonparametric</strong></p>
<p>t-Distributed Stochastic Neighbour Embedding (2008)</p>
<ul>
<li>Unsupervised non-linear technique</li>
<li>Things that are close remain close (?)</li>
<li>preserving only small pairwise distances or local similarities</li>
<li>Perplexity ~ a guess about the number of close neighbours each point has. 5-50</li>
<li>Creates 2D maps from multidimensional data</li>
<li>More computationally expensive</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="umap"><a class="header" href="#umap">UMAP</a></h1>
<p><strong>#nonparametric</strong> <strong>#nonprobabilistic</strong></p>
<p>Uniform Manifold Approximation and Projection</p>
<ol>
<li>The data is uniformly distributed on a Riemannian manifold;</li>
<li>The Riemannian metric is locally constant (or can be approximated as such);</li>
<li>The manifold is locally connected.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="similarity-measures"><a class="header" href="#similarity-measures">Similarity measures</a></h1>
<p>Distance metrics</p>
<h2 id="manhattan-distance"><a class="header" href="#manhattan-distance">Manhattan distance</a></h2>
<p>(shortest path by along a grid) L1 norm</p>
<p>$$
|A-B|
$$</p>
<p>or</p>
<p>$$
\sum_i |a_i-b_i|
$$</p>
<h2 id="euclidean-distance"><a class="header" href="#euclidean-distance">Euclidean distance</a></h2>
<p>(shortest path) L2 norm</p>
<p>$$
||A-B||_2
$$</p>
<p>or</p>
<p>$$
\sqrt{\sum_i (a_i-b_i)^2}
$$</p>
<h2 id="dot-product"><a class="header" href="#dot-product">Dot product</a></h2>
<p>$$
A \cdot B
$$</p>
<p>or</p>
<p>$$
\sum_i a_i b_i
$$</p>
<aside>
💡 Difference between dot product and inner product is that the dot product is a specific inner product that works on $\mathbb{R}^n$.
</aside>
<h2 id="cosine-similarity"><a class="header" href="#cosine-similarity">Cosine similarity</a></h2>
<p>(we are interested in the orientation, not the magnitude of vectors). Value is bounded between $[-1,1]$.</p>
<p>$$
\cos(\theta) = \frac{A \cdot B}{||A||\cdot||B||}
$$</p>
<p>or</p>
<p>$$
\cos(\theta) = \frac{\sum_i a_i b_i}{\sqrt{\sum_i a_i^2} \cdot \sqrt{\sum_i b_i^2}}
$$</p>
<aside>
💡 Difference between dot product and cosine similarity is that **cosine similarity ignores the magnitude** (scaled by magnitude).
</aside>
<h2 id="pearson-correlation"><a class="header" href="#pearson-correlation">Pearson correlation</a></h2>
<p>$$
\text{Corr}(a,b) = \frac{\sum_i (a_i-\bar{a})(b_i-\bar{b})}{\sqrt{\sum_i (a_i-\bar{a})^2} \cdot \sqrt{\sum_i (b_i-\bar{b})^2}}
$$</p>
<aside>
💡 Difference between cosine similarity and correlation is correlation is **invariant to shifts.**
</aside>
<h2 id="minkowski-distance"><a class="header" href="#minkowski-distance">Minkowski distance</a></h2>
<p>$L_p$ norm</p>
<p>$$
(\sum_i (a_i-b_i)^p)^\frac{1}{p}
$$</p>
<ul>
<li>Jaccard distance: compare the unique items</li>
<li>Mahalanobis distance</li>
<li>Maximum distance</li>
<li>Haversine distance - distance between 2 points on a sphere</li>
<li>Hamming distance</li>
<li>Levenshtein distance</li>
</ul>
<p><img src="./Euclidean_Distance.png" alt="Euclidean distance" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dimensionality-reduction"><a class="header" href="#dimensionality-reduction">Dimensionality reduction</a></h1>
<p>to create embeddings or projection of high-dimensional vector to 3D</p>
<p>(unsupervised learning)</p>
<p>Dimensionality reduction. Reducing the dimension helps us to visualise better</p>
<p>PCA - keep global distance</p>
<p>t-SNE - focus on local distance</p>
<p>UMAP - focus on local distance, but keep more global distance</p>
<p>Random projection</p>
<p>Runtime: tSNE&gt;UMAP≥PCA</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ann"><a class="header" href="#ann">ANN</a></h1>
<p>Approximate nearest neighbours</p>
<p>Fast computation of nearest neighbours is an active area of research. The most naive implementation i s the brute-force computation of distances between all pairs.</p>
<p><a href="http://ann-benchmarks.com/">http://ann-benchmarks.com</a></p>
<p>Fast approximate distance computations for vector similarity search</p>
<ul>
<li><a href="https://github.com/google-research/google-research/tree/master/scann">ScaNN</a></li>
<li>NGT-ONNG</li>
<li>hnswlib</li>
<li><a href="https://github.com/facebookresearch/faiss">FAISS</a></li>
<li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwik7vrY9oLrAhVLAXIKHfz3AC4QFjAAegQIAxAC&amp;url=https%3A%2F%2Fgithub.com%2Fspotify%2Fannoy&amp;usg=AOvVaw1EAessPsvKY5ftaBM6VmqC">ANNOY</a></li>
<li>scikit-learn: K-D tree, Ball Tree</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="survival-analysis"><a class="header" href="#survival-analysis">Survival analysis</a></h1>
<p>To measure any duration. Time-to-event analysis.</p>
<ul>
<li>How long does this population live for?</li>
<li>How long will a particular customer remain with your business? (After how much time will this customer churn?)</li>
<li>How long will this machine last, after successfully running for a year?</li>
</ul>
<p>Concepts</p>
<ul>
<li>Birth (= start)</li>
<li>Death (= end)</li>
<li>Survival probability</li>
</ul>
<p>At the time of inference, it is not</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concept-drift"><a class="header" href="#concept-drift">Concept drift</a></h1>
<p>data drift, label schema change, model drift</p>
<p><a href="https://twitter.com/chipro/status/1313921889061015557?s=20">https://twitter.com/chipro/status/1313921889061015557?s=20</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interpretable-ai"><a class="header" href="#interpretable-ai">Interpretable AI</a></h1>
<p>Explainable AI / Bias in AI</p>
<p>Resources</p>
<p><a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a></p>
<p><a href="https://github.com/jphall663/awesome-machine-learning-interpretability">https://github.com/jphall663/awesome-machine-learning-interpretability</a></p>
<p><a href="https://microscope.openai.com/models">https://microscope.openai.com/models</a></p>
<p><strong>Explainability</strong> refers to the understanding, in simple terms, of how exactly a model works under the hood.</p>
<p><strong>Interpretability</strong> refers to the ability of observing the effect that changes in the (i) input or (ii) parameters will have on predicted outputs</p>
<p>What is?</p>
<ul>
<li>Extracting insights to understand
<ul>
<li>Why did the model make such a prediction?</li>
<li>How does each feature affect a prediction? What if I did this?</li>
</ul>
</li>
</ul>
<p>For?</p>
<ul>
<li>Trust</li>
<li>Debugging</li>
<li>Future data collection</li>
<li>Feature engineering</li>
<li>Inform human decision-making</li>
</ul>
<p><strong>General</strong></p>
<ul>
<li>Model cards</li>
<li>explainx.ai</li>
</ul>
<h1 id="tabular"><a class="header" href="#tabular"><strong>Tabular</strong></a></h1>
<h2 id="feature-importance"><a class="header" href="#feature-importance"><strong>Feature importance</strong></a></h2>
<ul>
<li>Tree-based models</li>
<li>LIME</li>
<li>Permutation importance: shuffle the data within a column</li>
<li>Partial dependence plots: keep changing value for one variable</li>
<li>SHAP values (Shapley additive explanations): compare a value with baseline value</li>
<li>Integrated Gradients</li>
<li>DeepLift</li>
<li>Model-Agnostic Linear Competitors (MALC)</li>
<li><a href="https://github.com/pytorch/captum">Captum</a></li>
</ul>
<h2 id="constraining-nonlinear-models"><a class="header" href="#constraining-nonlinear-models"><strong>Constraining nonlinear models</strong></a></h2>
<ul>
<li>Contextual Decomposition Explanation Penalization (CDEP) add a term to the loss function so models can learn how to produce good explanations</li>
<li>MonoNet</li>
</ul>
<h2 id="interpretable-models"><a class="header" href="#interpretable-models"><strong>Interpretable models</strong></a></h2>
<ul>
<li>Decision trees: 
Information gain &amp; gini impurity. Splits that have the most impact on a prediction are kept closer to the root of the tree</li>
<li>Linear models
Implicitly interpretable, since they can naturally weight the influence of the weights. Perturbing the inputs or learned parameters has a predetermined effect on the outputs.</li>
<li>Logistic regression</li>
</ul>
<h1 id="image"><a class="header" href="#image"><strong>Image</strong></a></h1>
<p>Using feature visualisation and activation atlases</p>
<ul>
<li>
<p>Grad-CAM (Class activation map)</p>
<p>Grad-CAM works by (1) finding the final convolutional layer in the network and then (2) examining the gradient information flowing into that layer. Then multiply the signals with the outputs from (1).</p>
</li>
<li>
<p><a href="https://github.com/marcotcr/lime">LIME</a></p>
</li>
<li>
<p>Summit</p>
</li>
</ul>
<h1 id="text"><a class="header" href="#text"><strong>Text</strong></a></h1>
<ul>
<li>exBERT</li>
<li><a href="https://github.com/jalammar/ecco?utm_source=Deep+Learning+Weekly&amp;utm_campaign=6f762da6bd-EMAIL_CAMPAIGN_2019_04_24_03_18_COPY_01&amp;utm_medium=email&amp;utm_term=0_384567b42d-6f762da6bd-72969297">Ecco</a></li>
<li>Language Interpretability Tool by Google</li>
</ul>
<p>Libraries</p>
<ul>
<li>ELI5</li>
<li>pdpbox</li>
<li>shap</li>
<li>Uber’s manifold</li>
<li>What-If</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cs5260--neural-networks-and-deep-learning-ii"><a class="header" href="#cs5260--neural-networks-and-deep-learning-ii">CS5260 — Neural Networks and Deep Learning II</a></h1>
<hr />
<h1 id="adversarial-ml"><a class="header" href="#adversarial-ml">Adversarial ML</a></h1>
<p><a href="https://www.tensorflow.org/tutorials/generative/adversarial_fgsm">https://www.tensorflow.org/tutorials/generative/adversarial_fgsm</a></p>
<h2 id="intro"><a class="header" href="#intro">Intro</a></h2>
<p>a machine learning technique that attempts to fool models by supplying deceptive input</p>
<p>adversarial example = image + noise</p>
<ul>
<li>Self-driving cars: kill people</li>
<li>Spam classifiers</li>
<li>Biometric recognition — steal money eg. apple pay</li>
</ul>
<p>Given</p>
<p>$\tilde{x} = x + \eta$</p>
<p>where $\tilde{x}$ is the adversarial sample, $x$ is the image and $\eta$ is the perturbation,</p>
<p>then if</p>
<p>$$\eta_i &lt; \epsilon$$</p>
<p>$$||\eta||_\infty &lt; \epsilon$$</p>
<p>where $\eta$ is the number small enough to be discarded by the hardware, </p>
<p>we expect the model assigns the same class to both $x$ and $\tilde{x}$.</p>
<p>This also makes use of the fact that digital images often use 8 bits per pixel:</p>
<p>(0, 1/255, 2/255, ..., 255/255)</p>
<p><img src="Untitled.png" alt="Untitled" /></p>
<ul>
<li>Take-away
<ul>
<li>A simple linear model can have adversarial examples if its input has sufficient dimensionality</li>
</ul>
</li>
</ul>
<h2 id="how-to-attack"><a class="header" href="#how-to-attack">How to attack</a></h2>
<h3 id="fgsm-whitebox"><a class="header" href="#fgsm-whitebox">FGSM (whitebox)</a></h3>
<p>Fast Gradient Sign Method</p>
<p>attacker has complete access to the model (white box attack)</p>
<p><img src="Untitled%201.png" alt="Untitled" /></p>
<h3 id="one-step-target-class-method-whitebox"><a class="header" href="#one-step-target-class-method-whitebox">One-step target class method (whitebox)</a></h3>
<p><img src="Untitled%202.png" alt="Untitled" /></p>
<p><img src="Untitled%203.png" alt="Untitled" /></p>
<h3 id="build-a-substitute-model"><a class="header" href="#build-a-substitute-model">Build a substitute model</a></h3>
<blockquote>
<p>Black-box Attack, Papernot et al. AsiaCCS 2017</p>
</blockquote>
<p>based on a small no. of initial queries to the model in production</p>
<h2 id="how-to-defend"><a class="header" href="#how-to-defend">How to defend</a></h2>
<h3 id="adversarial-training"><a class="header" href="#adversarial-training">Adversarial training</a></h3>
<p><img src="Untitled%204.png" alt="Untitled" /></p>
<aside>
💡 Metric: “89.4% error rate on adversarial examples” — which is bad
</aside>
<p>Note that adversarial training can have a negative impact (lower accuracy on clean samples, compared to models that don;’t go through adversarial training)</p>
<p><img src="Untitled%205.png" alt="Must do fine-tuning together with adversarial training" /></p>
<p>Must do fine-tuning together with adversarial training</p>
<p>Recap: Batch normalisation</p>
<p><img src="Untitled%206.png" alt="Untitled" /></p>
<p><img src="Untitled%207.png" alt="Untitled" /></p>
<p>Use <strong>Disentangled Learning</strong> via an Auxiliary BN. Uses the <strong>AdvProp</strong> algorithm</p>
<p><img src="Untitled%208.png" alt="Motivation for this is that the 2 different samples have different distributions" /></p>
<p>Motivation for this is that the 2 different samples have different distributions</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
