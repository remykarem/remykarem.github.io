# Models

"Foundation language models" / PFM (Pretrained Foundation Models)

| Year | Model          | Arch            | Pretraining | Params     | Applications                                      |
| ---- | -------------- | --------------- | ----------- | ---------- | ------------------------------------------------- |
| 2023 | LLaMA          | ?               | ?           | 7B,13B,65B | ?                                                 |
| 2022 | GPT-3.5        | Decoder         | LM          | 175B       | Code generation, dialog                           |
|      | OPT            | ?               |             |            |                                                   |
|      | LAMDA          | Decoder         | LM          | 137B       | General language modelling                        |
|      | ChatGPT        | Decoder         | LM          | 175B       | Dialog                                            |
|      | BLOOM          | Decoder         | LM          | 176B       | Code generation                                   |
|      | Minerva        | Decoder         | LM          | 540B       | Mathematical reasoning                            |
|      | Chinchilla     | Decoder         | LM          | 70B        | Dialog                                            |
|      | PaLM           | Decoder         | LM          | 62B,540B   | (general language tasks)                          |
| 2021 | HTML           | Encoder/Decoder | DAE         | 400M       | HTML prompting                                    |
|      | Gopher         | Decoder         | LM          | 280B       | General language modelling                        |
| 2020 | GPT-3          | Decoder         | LM          | 175B       | Code generation, audio generation                 |
|      | Big Bird       | Encoder         | MLM         | -          | Longer sequence                                   |
|      | ELECTRA        | Encoder         | RTD         | 110M-330M  | Longer sequence                                   |
|      | mBART          | Encoder/Decoder | DAE         | 110M       | Translation                                       |
| 2019 | XLM-RoBERTa    | Encoder         | MLM         | 270M-550M  | Translation, cross-lingual tasks                  |
|      | BART           | Encoder/Decoder | DAE         | 110M       | Text generation                                   |
|      | ERNIE          | Encoder         | MLM         | 114M       | Entity recognition                                |
|      | GPT-2          | Decoder         | LM          | 1.5B       | Text generation, (general language tasks)         |
|      | Transformer XL | Decoder         | LM          | 151M       | (general language tasks)                          |
|      | RoBERTA        | Encoder         | MLM         | 356M       | Language understading, question answering         |
|      | T5             | Encoder/Decoder | DAE         | 11B        | MT, question answering, abstractive summarisation |
|      | Pegasus        | Encoder/Decoder | DAE,MLM     | 223M-568M  | Summarisation                                     |
|      | ALBERT         | Encoder         | MLM/NSP     | 12M-60M    | Language understading, question answering         |
|      | DistilBERT     | Encoder         | MLM/NSP     | 66M        | Language understading, question answering         |
|      | XLNet          | Decoder         | PLM         | 117-360M   | (general language tasks)                          |
| 2018 | BERT           | Encoder         | MLM/NSP     | 110M       | Language understading, question answering         |
|      | GPT            | Decoder         | LM          | 117M       | Text generation                                   |
| 2017 | Transformer    | Encoder+Decoder |             |            |
| ?    | ELMO           | RNN             | LM          |            |
| ?    | seq2seq        | RNN             |             |            |
| ?    | UniLM          | ?               |             |            |
| ?    | ERNIE          | ?               |             |            |

Encoder or Decoder refers to the Transformer encoder or decoder.
