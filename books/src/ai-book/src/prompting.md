# Prompting

Pre-trained language models can solve tasks using zero-shot or few-shot prompting as in the paper [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165).

This technique requires *prompt engineering* â€” designing tasks that look like the data the model has seen during training.

* Retrieval-Augemented QA
* Self-Ask - ([Press et al 2022](https://ofir.io/self-ask.pdf))
