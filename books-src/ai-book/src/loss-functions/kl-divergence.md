# KL divergence

Kullback-Leibler

$$
    \sum_{c \in C} p\left(x_{c}\right) \cdot \log
    \frac{p\left(x_{c}\right)}{q\left(x_{c}\right)}
$$

where $p$ is the true distribution and $q$ is an approximation.

The KL divergence between two probability distributions measures how much they diverge from each other.

Minimising this means optimising the probability distribution parameters to closely resemble that of the true distribution.

